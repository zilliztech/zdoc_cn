---
slug: /question-answering-using-zilliz-cloud-and-cohere
beta: FALSE
notebook: FALSE
type: origin
token: N7KvwFAe8i7XWZk5aEGchRsynJA
sidebar_position: 3
---

import Admonition from '@theme/Admonition';


# ä¸ Cohere é›†æˆæ­å»ºæ™ºèƒ½é—®ç­”ç³»ç»Ÿ

æœ¬æ–‡å°†æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ Zilliz Cloud å’Œ Cohere æ­å»ºåŸºäº [SQuAD æ•°æ®é›†](https://rajpurkar.github.io/SQuAD-explorer/) çš„é—®ç­”ç³»ç»Ÿã€‚å…¶ä¸­ï¼ŒZilliz Cloud è´Ÿè´£æä¾›å‘é‡æ•°æ®åº“ï¼ŒCohere è´Ÿè´£æä¾›è·å–æŒ‡å®šæ–‡å­—å‘é‡è¡¨ç¤ºçš„æ¥å£ã€‚

## å‡†å¤‡å·¥ä½œ{#before-you-start}

æœ¬ç¤ºä¾‹ä¸­çš„è„šæœ¬éœ€è¦å®‰è£… __pymilvus__ï¼Œ__cohere__ï¼Œ__pandas__ï¼Œ__numpy__ å’Œ __tqdm__ã€‚å…¶ä¸­ï¼Œ__pymilvus__ æ˜¯ Zilliz Cloudçš„ Python å®¢æˆ·ç«¯ï¼Œå¦‚æœä½ çš„ç³»ç»Ÿä¸­æ²¡æœ‰å®‰è£…å®ƒä»¬ï¼Œå¯ä»¥ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤å®Œæˆå®‰è£…ã€‚

```shell
pip install pymilvus cohere pandas numpy tqdm openai tiktoken
```

ç„¶åï¼Œä½ å¯ä»¥æŒ‰ç…§å¦‚ä¸‹æ–¹å¼åŠ è½½å®ƒä»¬ã€‚

```python
from pymilvus import connections, DataType, CollectionSchema, FieldSchema, Collection, utility
import cohere
import pandas
import numpy as np
from tqdm import tqdm
import time, os, json
```

## ä¸»è¦å‚æ•°{#parameters}

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€äº›ç¤ºä¾‹ä¸­å°†è¦ä½¿ç”¨çš„ä¸»è¦å‚æ•°ã€‚ä½ éœ€è¦æ ¹æ®å®é™…æƒ…å†µå’Œå‚æ•°æ—çš„æ³¨é‡Šå¡«å†™æˆ–æ›¿æ¢æˆç›¸åº”çš„å†…å®¹ã€‚

```python
__# 1. Set the The SQuAD dataset url.__
FILE = 'https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json' 

__# 2. Set up the name of the collection to be created.__
COLLECTION_NAME = 'question_answering_db'

__# 3. Set up the dimension of the embeddings.__
DIMENSION = 768

__# 4. Set the number of entities to create and the number of entities to insert at a time.__
COUNT = 5000
BATCH_SIZE = 96

__# 5. Set up the cohere api key__
COHERE_API_KEY = "YOUR_COHERE_API_KEY"

__# 6. Set up the connection parameters for your Zilliz Cloud cluster.__
URI = 'YOUR_CLUSTER_ENDPOINT'

__# 7. Set up the token for your Zilliz Cloud cluster.__
__# You can either use an API key or a set of cluster username and password joined by a colon.__
TOKEN = 'YOUR_CLUSTER_TOKEN'
```

å…³äºæœ¬ç¤ºä¾‹ä½¿ç”¨çš„æ¨¡å‹å’Œæ•°æ®é›†ï¼Œå¯ä»¥å‚è€ƒ [Cohere](https://cohere.ai/) å’Œ [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/)ã€‚

## å‡†å¤‡æ•°æ®{#prepare-dataset}

åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨SQuADæ•°æ®é›†åšä¸ºå›ç­”é—®é¢˜çš„ä¿¡æºã€‚æ•°æ®é›†çš„åŸå§‹æ ¼å¼ä¸ºJSONï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨__pandas__åŠ è½½è¯¥æ•°æ®é›†ã€‚

```python
# Download the dataset
dataset = pandas.read_json(FILE)

# Clean up the dataset by grabbing all the question answer pairs
simplified_records = []
for x in dataset['data']:
    for y in x['paragraphs']:
        for z in y['qas']:
            if len(z['answers']) != 0:
                simplified_records.append({'question': z['question'], 'answer': z['answers'][0]['text']})

# Grab the amount of records based on COUNT
simplified_records = pandas.DataFrame.from_records(simplified_records)
simplified_records = simplified_records.sample(n=min(COUNT, len(simplified_records)), random_state = 42)

# Check if the length of the cleaned dataset matches COUNT
print(len(simplified_records))
```

ä¸Šé¢è¿™æ®µä»£ç çš„è¾“å‡ºå¦‚ä¸‹

```python
5000
```

## åˆ›å»º Collection{#create-a-collection}

æˆ‘ä»¬éœ€è¦äº‹å…ˆåœ¨ Zilliz Cloud ä¸Šå‡†å¤‡å¥½ä¸€ä¸ª Clusterã€‚åœ¨è¿™ä¸€å°èŠ‚é‡Œï¼Œæˆ‘ä»¬å°†æ¼”ç¤ºå¦‚ä½•åœ¨è¿™ä¸ª Cluster é‡Œåˆ›å»ºä¸€ä¸ª Collection å¹¶ä¸ºå…¶åˆ›å»ºç´¢å¼•ã€‚

```python
# Connect to Zilliz Cloud and create a collection

connections.connect(
    alias='default',
    # Public endpoint obtained from Zilliz Cloud
    uri=URI,
    token=TOKEN
)

if COLLECTION_NAME in utility.list_collections():
    utility.drop_collection(COLLECTION_NAME)

fields = [
    FieldSchema(name='id', dtype=DataType.INT64, is_primary=True, auto_id=True),
    FieldSchema(name='original_question', dtype=DataType.VARCHAR, max_length=1000),
    FieldSchema(name='answer', dtype=DataType.VARCHAR, max_length=1000),
    FieldSchema(name='original_question_embedding', dtype=DataType.FLOAT_VECTOR, dim=DIMENSION)
]

schema = CollectionSchema(fields=fields)

collection = Collection(
    name=COLLECTION_NAME,
    schema=schema,
)

index_params = {
    'metric_type': 'L2',
    'index_type': 'AUTOINDEX',
    'params': {'nlist': 1024}
}

collection.create_index(
    field_name='original_question_embedding', 
    index_params=index_params
)

collection.load()
```

## æ’å…¥æ•°æ®{#insert-data}

å‘ Collection ä¸­æ’å…¥æˆ‘ä»¬å‡†å¤‡å¥½çš„æ•°æ®åˆ†ä¸ºå¦‚ä¸‹ä¸‰æ­¥ï¼š

- è¯»å–å‡†å¤‡å¥½çš„æ•°æ®é›†ã€‚

- è·å–æ•°æ®é›†ä¸­åŸå§‹é—®é¢˜å¯¹åº”çš„å‘é‡è¡¨ç¤ºã€‚

- å°†æ•°æ®æ’å…¥ä¹‹å‰åˆ›å»ºçš„ Collection ä¸­ã€‚

åœ¨æœ¬ç¤ºä¾‹ä¸­ï¼Œæ¯ä¸€æ¡æ•°æ®éƒ½åŒ…å«ä¸€ä¸ªåŸå§‹é—®é¢˜ï¼Œè¯¥é—®é¢˜çš„å‘é‡è¡¨ç¤ºåŠå¯¹åº”çš„å›ç­”ã€‚

```python
# Set up a Cohere client
cohere_client = cohere.Client(COHERE_API_KEY)

# Extract embeddings from questions using Cohere
def embed(texts, input_type):
    res = cohere_client.embed(texts, model='multilingual-22-12', input_type=input_type)
    return res.embeddings

# Insert each question, answer, and qustion embedding
total = pandas.DataFrame()
for batch in tqdm(np.array_split(simplified_records, (COUNT/BATCH_SIZE) + 1)):
    questions = batch['question'].tolist()
    embeddings = embed(questions, "search_document")
    
    data = [
        {
            'original_question': x,
            'answer': batch['answer'].tolist()[i],
            'original_question_embedding': embeddings[i]
        } for i, x in enumerate(questions)
    ]

    collection.insert(data=data)

time.sleep(10)
```

## æµ‹è¯•é—®ç­”{#ask-questions}

åœ¨æˆ‘ä»¬å‘ Collection ä¸­æ’å…¥æ‰€æœ‰çš„æ•°æ®åï¼Œå°±å¯ä»¥å¼€å§‹å‘è¿™ä¸ªé—®ç­”ç³»ç»Ÿæé—®äº†ã€‚æé—®çš„è¿‡ç¨‹ä¹Ÿåˆ†ä¸ºä¸‰æ­¥ï¼Œåˆ†åˆ«æ˜¯ï¼š

- æå‡ºé—®é¢˜

- ä½¿ç”¨ Cohere è·å–è¯¥é—®é¢˜çš„å‘é‡è¡¨ç¤º

- ä½¿ç”¨ Zilliz Cloud å¯¹è¯¥å‘é‡è¡¨ç¤ºè¿›è¡Œç›¸ä¼¼æ€§æœç´¢

<Admonition type="info" icon="ğŸ“˜" title="è¯´æ˜">

<p>åœ¨æ•°æ®æ’å…¥åç«‹å³è¿›è¡Œæœç´¢å¯èƒ½ä¼šæ¯”è¾ƒæ…¢ã€‚å› ä¸ºåœ¨æ•°æ®å®Œæˆç´¢å¼•å‰ï¼ŒZilliz Cloud ä¼šä½¿ç”¨æš´åŠ›æœç´¢çš„æ–¹å¼åœ¨è¿™äº›æ•°æ®ä¸­æŸ¥æ‰¾ç›¸ä¼¼çš„ç»“æœã€‚å½“æ‰€æœ‰æ•°æ®å‡å®Œæˆç´¢å¼•åï¼Œæœç´¢é€Ÿåº¦ä¼šå˜å¿«ã€‚</p>

</Admonition>

```python
# Search the cluster for an answer to a question text
def search(text, top_k = 5):

    # AUTOINDEX does not require any search params 
    search_params = {}

    results = collection.search(
        data = embed([text], "search_query"),  # Embeded the question
        anns_field='original_question_embedding',
        param=search_params,
        limit = top_k,  # Limit to top_k results per search
        output_fields=['original_question', 'answer']  # Include the original question and answer in the result
    )

    distances = results[0].distances
    entities = [ x.entity.to_dict()['entity'] for x in results[0] ]

    ret = [ {
        "answer": x[1]["answer"],
        "distance": x[0],
        "original_question": x[1]['original_question']
    } for x in zip(distances, entities)]

    return ret

# Ask these questions
search_questions = ['What kills bacteria?', 'What\'s the biggest dog?']

# Print out the results in order of [answer, similarity score, original question]

ret = [ { "question": x, "candidates": search(x) } for x in search_questions ]

print(ret)
```

æœ¬ç¤ºä¾‹è¿”å›çš„æœç´¢ç»“æœå¦‚ä¸‹ï¼š

```python
# Output
#
# [
#     {
#         "question": "What kills bacteria?",
#         "candidates": [
#             {
#                 "answer": "farming",
#                 "distance": 25.10422134399414,
#                 "original_question": "What makes bacteria resistant to antibiotic treatment?"
#             },
#             {
#                 "answer": "converting nitrogen gas to nitrogenous compounds",
#                 "distance": 25.26958465576172,
#                 "original_question": "What do bacteria do in soil?"
#             },
#             {
#                 "answer": "slowing down the multiplication of bacteria or killing the bacteria",
#                 "distance": 26.225540161132812,
#                 "original_question": "How do antibiotics work?"
#             },
#             {
#                 "answer": "Phage therapy",
#                 "distance": 30.04580307006836,
#                 "original_question": "What has been talked about to treat resistant bacteria?"
#             },
#             {
#                 "answer": "antibiotic target",
#                 "distance": 32.077369689941406,
#                 "original_question": "What can be absent from the bacterial genome?"
#             }
#         ]
#     },
#     {
#         "question": "What's the biggest dog?",
#         "candidates": [
#             {
#                 "answer": "English Mastiff",
#                 "distance": 12.71607780456543,
#                 "original_question": "What breed was the largest dog known to have lived?"
#             },
#             {
#                 "answer": "part of the family",
#                 "distance": 27.21062469482422,
#                 "original_question": "Most people today describe their dogs as what?"
#             },
#             {
#                 "answer": "77.5 million",
#                 "distance": 28.54041290283203,
#                 "original_question": "How many people in the United States are said to own dog?"
#             },
#             {
#                 "answer": "Rico",
#                 "distance": 28.770610809326172,
#                 "original_question": "What is the name of the dog that could ID over 200 things?"
#             },
#             {
#                 "answer": "about six",
#                 "distance": 31.739566802978516,
#                 "original_question": "What is the average number of pups in a litter?"
#             }
#         ]
#     }
# ]
```
