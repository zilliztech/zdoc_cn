---
slug: /image-search-with-zilliz-cloud-and-pytorch
beta: FALSE
notebook: FALSE
type: origin
token: FpeXw3b5piUAG7kUCgucgI1unFh
sidebar_position: 5
---

import Admonition from '@theme/Admonition';


# ä¸ PyTorch é›†æˆæ­å»ºå›¾ç‰‡æœç´¢ç³»ç»Ÿ

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ Zilliz Cloud æ­å»ºä¸€ä¸ªç®€å•çš„å›¾ç‰‡æœç´¢ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿä½¿ç”¨çš„æ•°æ®é›†æ˜¯ [Kaggle](https://www.kaggle.com/datasets/delayedkarma/impressionist-classifier-data) ä¸Šæä¾›çš„å°è±¡æ´¾å¤§å¸ˆåˆ†ç±»å™¨æ•°æ®é›†ï¼ˆ Impressionist-Classifier Dataset ï¼‰ã€‚åœ¨æœ¬ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†è¯¥æ•°æ®åº“é‡æ–°æ‰˜ç®¡åˆ°äº†ä¸€ä¸ªå…¬å…±çš„ Google Drive ä¸­ã€‚

æœ¬ç¤ºä¾‹éœ€è¦ä½¿ç”¨ä¸€ä¸ª 1 CU çš„ Zilliz Cloud Clusterï¼Œå¹¶ä½¿ç”¨ PyTorch çš„é¢„è®­ç»ƒ ResNet50 æ¨¡å‹è·å–æŒ‡å®šå›¾ç‰‡çš„å‘é‡è¡¨ç¤ºã€‚

ç°åœ¨ï¼Œè®©æˆ‘ä»¬å¼€å§‹å§ï¼

## å‡†å¤‡å·¥ä½œ{#before-you-start}

æœ¬é¡µä¸­çš„è„šæœ¬éœ€è¦ä½¿ç”¨ **pymilvus** è¿æ¥ Zilliz Cloudï¼Œä½¿ç”¨ **torch** è¿è¡Œ Embedding æ¨¡å‹ï¼Œä½¿ç”¨ **torchvision** è°ƒç”¨æ¨¡å‹å¹¶å¯¹å›¾ç‰‡è¿›è¡Œé¢„å¤„ç†ï¼Œä½¿ç”¨ **gdown** ä¸‹è½½ç¤ºä¾‹æ•°æ®é›†ï¼Œä½¿ç”¨ tqdm åœ¨å‘½ä»¤è¡Œä¸­æ˜¾ç¤ºè¿›åº¦æ¡ã€‚æˆ‘ä»¬å¯ä»¥è¿è¡Œå¦‚ä¸‹å‘½ä»¤å®‰è£…è¿™äº›ä¾èµ–ã€‚

```shell
pip install pymilvus torch gdown torchvision tqdm
```

## å‡†å¤‡æ•°æ®{#prepare-data}

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨ **gdown** ä»å…¬å…± Google Drive ä¸­è·å–å‹ç¼©æ–‡ä»¶ï¼Œå¹¶ä½¿ç”¨ Python è‡ªå¸¦çš„ **zipfile** åŒ…å°†å…¶è§£å‹ã€‚

```python
import gdown
import zipfile

url = 'https://drive.google.com/uc?id=1OYDHLEy992qu5C4C8HV5uDIkOWRTAR1_'
output = './paintings.zip'
gdown.download(url, output)

with zipfile.ZipFile("./paintings.zip","r") as zip_ref:
    zip_ref.extractall("./paintings")
```

<Admonition type="info" icon="ğŸ“˜" title="è¯´æ˜">

<p>æ•°æ®é›†å¤§å°ä¸º 2.35 GB , ä¸‹è½½è€—æ—¶å–å†³äºæ‚¨çš„ç½‘ç»œçŠ¶å†µã€‚</p>

</Admonition>

## ä¸»è¦å‚æ•°{#parameters}

ä¸ºäº†æ›´å¥½çš„ç®¡ç†è„šæœ¬ï¼Œæˆ‘ä»¬å°†ä¸€äº›ä¸»è¦çš„å…¬å…±å‚æ•°æå–å‡ºæ¥åˆ—åœ¨ä¸‹æ–¹ã€‚ä½ å¯ä»¥æ ¹æ®éœ€è¦ä¿®æ”¹è¿™äº›å‚æ•°ã€‚

```python
# 1. Set up the name of the collection to be created.
COLLECTION_NAME = 'image_search_db'

# 2. Set up the dimension of the embeddings.
DIMENSION = 2048

# 3. Set the inference parameters
BATCH_SIZE = 128
TOP_K = 3

# 4. Set up the connection parameters for your Zilliz Cloud cluster.
URI = 'YOUR_CLUSTER_ENDPOINT'
TOKEN = 'YOUR_CLUSTER_TOKEN'
```

## è®¾ç½® Zilliz Cloud{#setting-up-zilliz-cloud}

åœ¨è¿™ä¸€å°èŠ‚ï¼Œæˆ‘ä»¬å°†å®Œæˆ Zilliz Cloud çš„è®¾ç½®ï¼Œæ¶‰åŠå¦‚ä¸‹æ­¥éª¤ï¼š

1. ä½¿ç”¨æä¾›çš„ç«¯ç‚¹ URI è¿æ¥ Zilliz Cloud clusterã€‚

    ```python
    from pymilvus import connections
    
    # Connect to Zilliz Cloud and create a collection
    connections.connect(
        alias='default',
        # Public endpoint obtained from Zilliz Cloud
        uri=URI,
        token=TOKEN
    )
    ```

1. å¦‚æœéœ€è¦åˆ›å»ºçš„ Collection å·²å­˜åœ¨ï¼Œåˆ é™¤è¯¥ Collectionã€‚

    ```python
    from pymilvus import utility
    
    # Remove any previous collections with the same name
    if COLLECTION_NAME in utility.list_collections():
        utility.drop_collection(COLLECTION_NAME)
    ```

1. åˆ›å»ºä¸€ä¸ª Collection ç”¨äºå­˜å‚¨å›¾ç‰‡ IDï¼Œå›¾ç‰‡è·¯å¾„ä»¥åŠè¯¥å›¾ç‰‡çš„å‘é‡è¡¨ç¤ºã€‚

    ```python
    from pymilvus import FieldSchema, CollectionSchema, DataType, Collection
    
    fields = [
        FieldSchema(name='id', dtype=DataType.INT64, is_primary=True, auto_id=True),
        FieldSchema(name='filepath', dtype=DataType.VARCHAR, max_length=200),  *# VARCHARS need a maximum length, so for this example they are set to 200 characters*
        FieldSchema(name='image_embedding', dtype=DataType.FLOAT_VECTOR, dim=DIMENSION)
    ]
    
    schema = CollectionSchema(fields=fields)
    
    collection = Collection(
        name=COLLECTION_NAME,
        schema=schema,
    )
    ```

1. ä¸º Collection åˆ›å»ºç´¢å¼•æ–‡ä»¶ï¼Œå¹¶å°† Collection åŠ è½½åˆ°å†…å­˜ã€‚

    ```python
    index_params = {
        'index_type': 'AUTOINDEX',
        'metric_type': 'L2',
        'params': {}
    }
    
    collection.create_index(
        field_name='image_embedding', 
        index_params=index_params
    )
    
    collection.load()
    ```

åœ¨å®Œæˆä¸Šè¿°æ­¥éª¤åï¼Œæˆ‘ä»¬å°±å¯ä»¥å‘ Collection ä¸­æ’å…¥æ•°æ®äº†ã€‚åœ¨åˆ›å»ºç´¢å¼•æ–‡ä»¶åæ’å…¥çš„ä»»ä½•æ•°æ®éƒ½ä¼šè¢«è‡ªåŠ¨ç´¢å¼•å¹¶å¯è¢«ç«‹å³ç”¨äºæœç´¢ã€‚å¦‚æœæ•°æ®æ­£åœ¨ç´¢å¼•è¿‡ç¨‹ä¸­ï¼ŒZilliz Cloud ä¼šä½¿ç”¨æš´åŠ›æœç´¢æ¨¡å¼ï¼Œæ‰€ä»¥æœç´¢è¿‡ç¨‹å¯èƒ½ä¼šæ¯”è¾ƒæ…¢ã€‚

## æ’å…¥æ•°æ®{#insert-data}

åœ¨æœ¬ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ **torch** åŒ…ä¸­çš„ ResNet50 æ¨¡å‹ã€‚ä¸ºäº†è·å–æŒ‡å®šå›¾ç‰‡çš„å‘é‡è¡¨ç¤ºï¼Œæˆ‘ä»¬å°†ç§»é™¤æ¨¡å‹çš„æœ€åä¸€ä¸ªåˆ†ç±»å±‚ã€‚è¿™æ ·ä¸€æ¥ï¼Œç»è¿‡æ¨¡å‹è·å–çš„å‘é‡ç»´åº¦å‡ä¸º2048ã€‚ä¸‹åˆ—ä»£ç å—ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº† torch åŒ…ä¸­æ‰€æœ‰æ¨¡å‹å‡ä¼šä½¿ç”¨ç›¸åŒçš„é¢„å¤„ç†æ–¹æ³•ã€‚

åœ¨ä¸‹åˆ—æ­¥éª¤ä¸­ï¼Œæˆ‘ä»¬å°†ä¼šï¼š

1. åŠ è½½æ•°æ®ã€‚

    ```python
    import glob
    
    # Get the filepaths of the images
    paths = glob.glob('./paintings/paintings/**/*.jpg', recursive=True)
    len(paths)
    
    # Output
    #
    # 4978
    ```

1. é¢„å¤„ç†æ•°æ®ï¼Œå°†å…¶åˆ†ä¸ºä¸åŒçš„æ‰¹æ¬¡ã€‚

    ```python
    import torch
    
    # åŠ è½½ Embedding æ¨¡å‹ï¼Œå¹¶ç§»é™¤æ¨¡å‹çš„æœ€åä¸€å±‚ã€‚
    model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)
    model = torch.nn.Sequential(*(list(model.children())[:-1]))
    model.eval()
    ```

1. è·å–æ•°æ®çš„å‘é‡è¡¨ç¤ºã€‚

    ```python
    from torchvision import transforms
    
    # å¯¹å›¾ç‰‡è¿›è¡Œé¢„å¤„ç†ã€‚
    preprocess = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    ```

1. å‘ Collection æ’å…¥æ•°æ®ã€‚

    ```python
    from PIL import Image
    from tqdm import tqdm
    
    # Embed function that embeds the batch and inserts it
    def embed(data):
        with torch.no_grad():
            output = model(torch.stack(data[0])).squeeze()
            collection.insert([data[1], output.tolist()])
    
    data_batch = [[],[]]
    
    # Read the images into batches for embedding and insertion
    for path in tqdm(paths):
        im = Image.open(path).convert('RGB')
        data_batch[0].append(preprocess(im))
        data_batch[1].append(path)
        if len(data_batch[0]) % BATCH_SIZE == 0:
            embed(data_batch)
            data_batch = [[],[]]
    
    # Embed and insert the remainder
    if len(data_batch[0]) != 0:
        embed(data_batch)
    
    # Call a flush to index any unsealed segments.
    time.sleep(5)
    ```

<Admonition type="info" icon="ğŸ“˜" title="è¯´æ˜">

<p>ç”±äºè·å–å›¾ç‰‡çš„å‘é‡è¡¨ç¤ºè€—æ—¶è¾ƒé•¿ï¼Œæœ¬æ­¥éª¤ç›¸å¯¹æ¯”è¾ƒè€—æ—¶ã€‚å¯ä»¥å–ç‚¹å’–å•¡ï¼Œç¨äº‹ä¼‘æ¯ã€‚</p>
<p>PyTorch å¯èƒ½ä¸ Python 3.9 åŠä¹‹å‰ç‰ˆæœ¬å­˜åœ¨ä¸å…¼å®¹çš„é—®é¢˜ã€‚å»ºè®®ä½¿ç”¨ Python 3.10 åŠä¹‹åç‰ˆæœ¬ã€‚</p>

</Admonition>

## æ‰§è¡Œæœç´¢{#perform-search}

åœ¨å‘ Zilliz Cloud æ’å…¥æ‰€æœ‰æ•°æ®åï¼Œæˆ‘ä»¬å°±å¯ä»¥å¼€å§‹æ‰§è¡Œæœç´¢äº†ã€‚åœ¨æœ¬ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸¤å¼ ç¤ºä¾‹å›¾ç‰‡æ‰§è¡Œç›¸ä¼¼æ€§æœç´¢ã€‚ç”±äºä»£ç ä¸­æ‰§è¡Œçš„æ˜¯æ‰¹é‡æœç´¢ï¼Œå› æ­¤æœç´¢æ—¶é—´æ˜¯æŒ‡å®ŒæˆåŒä¸€æ‰¹æ¬¡ä¸­æ‰€æœ‰å›¾ç‰‡çš„ç›¸ä¼¼æ€§æœç´¢çš„æ—¶é—´ã€‚

```python
import glob

# Get the filepaths of the search images
search_paths = glob.glob('./paintings/test_paintings/**/*.jpg', recursive=True)
print(len(search_paths))

# Output
#
# 2

import time
from matplotlib import pyplot as plt

# Embed the search images
def embed(data):
    with torch.no_grad():
        ret = model(torch.stack(data))
        # If more than one image, use squeeze
        if len(ret) > 1:
            return ret.squeeze().tolist()
        # Squeeze would remove batch for single image, so using flatten
        else:
            return torch.flatten(ret, start_dim=1).tolist()

data_batch = [[],[]]

for path in search_paths:
    im = Image.open(path).convert('RGB')
    data_batch[0].append(preprocess(im))
    data_batch[1].append(path)

embeds = embed(data_batch[0])
start = time.time()
res = collection.search(embeds, anns_field='image_embedding', param={}, limit=TOP_K, output_fields=['filepath'])
finish = time.time()

# Show the image results
f, axarr = plt.subplots(len(data_batch[1]), TOP_K + 1, figsize=(20, 10), squeeze=False)

for hits_i, hits in enumerate(res):
    axarr[hits_i][0].imshow(Image.open(data_batch[1][hits_i]))
    axarr[hits_i][0].set_axis_off()
    axarr[hits_i][0].set_title('Search Time: ' + str(finish - start))
    for hit_i, hit in enumerate(hits):
        axarr[hits_i][hit_i + 1].imshow(Image.open(hit.entity.get('filepath')))
        axarr[hits_i][hit_i + 1].set_axis_off()
        axarr[hits_i][hit_i + 1].set_title('Distance: ' + str(hit.distance))

# Save the search result in a separate image file alongside your script.
plt.savefig('search_result.png')
```

æœ¬ç¤ºä¾‹çš„æœç´¢ç»“æœå¦‚ä¸‹ã€‚

![XMxqbJd9io3Vx3x8Qcocj7avn2f](/img/XMxqbJd9io3Vx3x8Qcocj7avn2f.png)

