---
title: "æ•°æ®å¯¼å…¥æŒ‡å— | Cloud"
slug: /data-import-zero-to-hero
sidebar_label: "ç”¨æˆ·æŒ‡å—"
beta: FALSE
added_since: FALSE
last_modified: FALSE
deprecate_since: FALSE
notebook: FALSE
description: "æœ¬å°èŠ‚ä¸ºä¸€ä¸ªå¿«é€Ÿå¼•å¯¼æ•™ç¨‹ï¼Œæ—¨åœ¨å¸®åŠ©æ‚¨åœ¨ Zilliz Cloud ä¸Šå¿«é€Ÿå¼€å§‹åŒ…å«æ•°æ®å‡†å¤‡ã€å»ºç«‹ Collection åˆ°å¼€å§‹å¯¼å…¥æ•°æ®ç­‰å­ä»»åŠ¡åœ¨å†…çš„å…¨æµç¨‹æ•°æ®å¯¼å…¥ä»»åŠ¡ã€‚é€šè¿‡æœ¬èŠ‚ï¼Œä½ å°†æŒæ¡ï¼š | Cloud"
type: origin
token: FXGWwcjyViaQm8kvJgScITzBnr3
sidebar_position: 5
keywords: 
  - å‘é‡æ•°æ®åº“
  - zilliz
  - milvus
  - å¤§æ¨¡å‹å‘é‡æ•°æ®åº“
  - æ•°æ®å¯¼å…¥
  - æŒ‡å—

---

import Admonition from '@theme/Admonition';
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# æ•°æ®å¯¼å…¥æŒ‡å—

æœ¬å°èŠ‚ä¸ºä¸€ä¸ªå¿«é€Ÿå¼•å¯¼æ•™ç¨‹ï¼Œæ—¨åœ¨å¸®åŠ©æ‚¨åœ¨ Zilliz Cloud ä¸Šå¿«é€Ÿå¼€å§‹åŒ…å«æ•°æ®å‡†å¤‡ã€å»ºç«‹ Collection åˆ°å¼€å§‹å¯¼å…¥æ•°æ®ç­‰å­ä»»åŠ¡åœ¨å†…çš„å…¨æµç¨‹æ•°æ®å¯¼å…¥ä»»åŠ¡ã€‚é€šè¿‡æœ¬èŠ‚ï¼Œä½ å°†æŒæ¡ï¼š

- å¦‚ä½•å®šä¹‰ Schema åŠåˆ›å»ºå¯¼å…¥ä»»åŠ¡çš„ç›®æ ‡ Collection

- å¦‚ä½•ä½¿ç”¨ **BulkWriter** å‡†å¤‡æºæ•°æ®å¹¶å°†å…¶å†™å…¥è¿œç¨‹å¯¹è±¡å­˜å‚¨æ¡¶

- å¦‚æœè°ƒç”¨æ‰¹é‡å¯¼å…¥ API å°†å‡†å¤‡å¥½çš„æºæ•°æ®å¯¼å…¥ç›®æ ‡ Collection

## å¼€å§‹ä¹‹å‰{#before-you-start}

ä¸ºäº†ä¿è¯æ•´ä¸ªæ•°æ®å¯¼å…¥æµç¨‹çš„è¿ç»­æ€§ï¼Œè¯·åœ¨å¼€å§‹æœ¬æ•™ç¨‹å‰å®Œæˆå¦‚ä¸‹å‡†å¤‡å·¥ä½œï¼š

### åœ¨ Zilliz Cloud ä¸Šåˆ›å»ºé›†ç¾¤{#set-up-your-zilliz-cloud-cluster}

- å¦‚æœæ‚¨è¿˜æœªåˆ›å»ºä»»ä½•é›†ç¾¤ï¼Œå‚è€ƒ[æ­¤å¤„åˆ›å»ºä¸€ä¸ªé›†ç¾¤](./create-cluster-on-demand)ã€‚

- æ”¶é›†å¦‚ä¸‹ä¿¡æ¯ï¼š**é›†ç¾¤ Endpoint**ã€**API å¯†é’¥**ã€**é›†ç¾¤ ID**ã€‚

### å®‰è£…ä¾èµ–{#install-dependencies}

<Tabs groupId="code" defaultValue='python' values={[{"label":"Python","value":"python"},{"label":"Java","value":"java"}]}>

<TabItem value='python'>

åœ¨ç»ˆç«¯ä¸­è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£… **pymilvus** å’Œ **minio** æˆ–å°†å®ƒä»¬å‡çº§åˆ°æœ€æ–°çš„ç‰ˆæœ¬ã€‚

```shell
python3 -m pip install --upgrade pymilvus minio
```

</TabItem>

<TabItem value='java'>

- å¦‚æ‚¨ä½¿ç”¨ Apache Maven ç®¡ç†é¡¹ç›®, åœ¨é¡¹ç›®çš„ **pom.xml** æ–‡ä»¶ä¸­æ·»åŠ å¦‚ä¸‹å†…å®¹ï¼š

```java
<dependency>
  <groupId>io.milvus</groupId>
  <artifactId>milvus-sdk-java</artifactId>
  <version>2.4.8</version>
</dependency>
```

- å¦‚æ‚¨ä½¿ç”¨ Gradle/Grails ç®¡ç†é¡¹ç›®, æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ï¼š

```shell
compile 'io.milvus:milvus-sdk-java:2.4.8'
```

</TabItem>

</Tabs>

### é…ç½®è¿œç¨‹å¯¹è±¡å­˜å‚¨æ¡¶{#configure-your-remote-storage-bucket}

- åœ¨æ‚¨çš„é˜¿é‡Œäº‘æˆ–è…¾è®¯äº‘æ§åˆ¶å°ä¸Šåˆ›å»ºä¸€ä¸ªå¯¹è±¡å­˜å‚¨æ¡¶ã€‚

- è®°å½•ä¸‹è®¿é—®è¯¥å¯¹è±¡å­˜å‚¨æ¡¶çš„ **Access Key**ã€**Secret Key** ä»¥åŠ**æ¡¶åç§°**ã€‚æ‚¨å¯ä»¥åœ¨é˜¿é‡Œäº‘æ§åˆ¶å°ä¸­æ‰¾åˆ°è¿™äº›ä¿¡æ¯ã€‚

ä¸ºäº†æ›´å¥½åœ°åˆ©ç”¨æœ¬æ•™ç¨‹ä¸­çš„ç¤ºä¾‹ä»£ç ï¼Œå»ºè®®æ‚¨ä½¿ç”¨æ”¶é›†åˆ°çš„ä¿¡æ¯è®¾ç½®å¦‚ä¸‹å˜é‡ï¼š

<Tabs groupId="code" defaultValue='python' values={[{"label":"Python","value":"python"},{"label":"Java","value":"java"}]}>
<TabItem value='python'>

```python
## The value of the URL is fixed.
CLOUD_API_ENDPOINT = "https://api.cloud.zilliz.com.cn"
API_KEY=""

# Configs for Zilliz Cloud cluster
CLUSTER_ENDPOINT=""
CLUSTER_ID="" # Zilliz Cloud cluster ID, like "in01-xxxxxxxxxxxxxxx"
COLLECTION_NAME="zero_to_hero"

# Configs for remote bucket
BUCKET_NAME=""
ACCESS_KEY=""
SECRET_KEY=""
```

</TabItem>

<TabItem value='java'>

```java
/**
 * The value of the URL is fixed.
 */
String CLOUD_API_ENDPOINT = "https://api.cloud.zilliz.com.cn";
String API_KEY = "";

// Configs for Zilliz Cloud cluster
String CLUSTER_ENDPOINT = "";
String CLUSTER_ID = ""; // Zilliz Cloud cluster ID, like "in01-xxxxxxxxxxxxxxx"
String COLLECTION_NAME = "zero_to_hero";

// Configs for remote bucket
String BUCKET_NAME = "";
String ACCESS_KEY = "";
String SECRET_KEY = "";
```

</TabItem>
</Tabs>

## åˆ›å»ºç›®æ ‡ Collection Schema{#set-up-target-collection-schema}

æˆ‘ä»¬å¯ä»¥æ ¹æ®ä¸Šè¡¨çš„å†…å®¹è®¾è®¡ç›®æ ‡ Collection çš„ Schemaã€‚

ä¸ºäº†æ›´å¥½åœ°æ¼”ç¤º Collection çš„èƒ½åŠ›ï¼Œæˆ‘ä»¬åœ¨ç›®æ ‡ Collection çš„ Schema ä¸­åŒ…å«äº†å‰ 4 ä¸ªå­—æ®µï¼Œå¹¶å°†å 4 ä¸ªå­—æ®µåšä¸ºåŠ¨æ€å­—æ®µä½¿ç”¨ã€‚

<Tabs groupId="code" defaultValue='python' values={[{"label":"Python","value":"python"},{"label":"Java","value":"java"}]}>

<TabItem value='python'>

```python
from pymilvus import MilvusClient, DataType

# You need to work out a collection schema out of your dataset.
schema = MilvusClient.create_schema(
    auto_id=False,
    enable_dynamic_field=True
)

DIM = 512

schema.add_field(field_name="id", datatype=DataType.INT64, is_primary=True),
schema.add_field(field_name="bool", datatype=DataType.BOOL),
schema.add_field(field_name="int8", datatype=DataType.INT8),
schema.add_field(field_name="int16", datatype=DataType.INT16),
schema.add_field(field_name="int32", datatype=DataType.INT32),
schema.add_field(field_name="int64", datatype=DataType.INT64),
schema.add_field(field_name="float", datatype=DataType.FLOAT),
schema.add_field(field_name="double", datatype=DataType.DOUBLE),
schema.add_field(field_name="varchar", datatype=DataType.VARCHAR, max_length=512),
schema.add_field(field_name="json", datatype=DataType.JSON),
schema.add_field(field_name="array_str", datatype=DataType.ARRAY, max_capacity=100, element_type=DataType.VARCHAR, max_length=128)
schema.add_field(field_name="array_int", datatype=DataType.ARRAY, max_capacity=100, element_type=DataType.INT64)
schema.add_field(field_name="float_vector", datatype=DataType.FLOAT_VECTOR, dim=DIM),
schema.add_field(field_name="binary_vector", datatype=DataType.BINARY_VECTOR, dim=DIM),
schema.add_field(field_name="float16_vector", datatype=DataType.FLOAT16_VECTOR, dim=DIM),
# schema.add_field(field_name="bfloat16_vector", datatype=DataType.BFLOAT16_VECTOR, dim=DIM),
schema.add_field(field_name="sparse_vector", datatype=DataType.SPARSE_FLOAT_VECTOR)

schema.verify()

print(schema)
```

ä¸Šè¿°ä»£ç ä¸­çš„å­—æ®µè§£é‡Šå¦‚ä¸‹ï¼š

- `fields`:

    - `id` æ˜¯ä¸»é”®ã€‚

    - `title_vector` ç”¨äºå­˜å‚¨ 768 ç»´çš„å‘é‡æ•°æ®ã€‚

    - `title` å’Œ `link` æ˜¯ä¸¤ä¸ªæ ‡é‡å­—æ®µã€‚

- `auto_id=False`

    è¯¥å‚æ•°é»˜è®¤å€¼ä¸º **False**ï¼Œè¡¨ç¤ºä¸»é”®ä¸ä¼šéšæ•°æ®æ’å…¥è‡ªåŠ¨å¢é•¿ã€‚å°†å…¶è®¾ç½®ä¸º **True** å¯é˜»æ­¢ **BulkWriter** åœ¨ç”Ÿæˆçš„æ–‡ä»¶ä¸­åŒ…å«ä¸»é”®ã€‚

- `enable_dynamic_field=True`

    è¯¥å‚æ•°é»˜è®¤ä¸º **False**ï¼Œè¡¨ç¤º Schema ä¸­æœªå®šä¹‰çš„å­—æ®µå°†ä¼šè¢«å¿½ç•¥ã€‚å°†å…¶è®¾ç½®ä¸º **True** å°†å…è®¸ **BulkWriter** å°†æœªåœ¨ Schema ä¸­å®šä¹‰çš„å­—æ®µä»¥é”®å€¼å¯¹çš„å½¢å¼å­˜å‚¨åˆ°ä¸€ä¸ªåä¸º **&#36;meta** çš„é¢„ç•™ JSON å­—æ®µä¸­ã€‚

</TabItem>

<TabItem value='java'>

```java
import com.google.gson.Gson;
import com.google.gson.JsonObject;
import io.milvus.bulkwriter.BulkImport;
import io.milvus.bulkwriter.RemoteBulkWriter;
import io.milvus.bulkwriter.RemoteBulkWriterParam;
import io.milvus.bulkwriter.common.clientenum.BulkFileType;
import io.milvus.bulkwriter.common.clientenum.CloudStorage;
import io.milvus.bulkwriter.connect.S3ConnectParam;
import io.milvus.bulkwriter.connect.StorageConnectParam;
import io.milvus.bulkwriter.request.describe.MilvusDescribeImportRequest;
import io.milvus.bulkwriter.request.import_.MilvusImportRequest;
import io.milvus.bulkwriter.request.list.MilvusListImportJobsRequest;
import io.milvus.common.utils.Float16Utils;
import io.milvus.v2.client.ConnectConfig;
import io.milvus.v2.client.MilvusClientV2;
import io.milvus.v2.common.DataType;
import io.milvus.v2.service.collection.request.*;

import java.io.IOException;
import java.nio.ByteBuffer;
import java.util.*;
import java.util.concurrent.TimeUnit;

private static final String STORAGE_ENDPOINT = CloudStorage.AWS.getEndpoint();
private static final String BUCKET_NAME = "a-bucket";
private static final String ACCESS_KEY = "access-key";
private static final String SECRET_KEY = "secret-key";

private static final Integer DIM = 512;
private static final Gson GSON_INSTANCE = new Gson();

private static CreateCollectionReq.CollectionSchema createSchema() {
    CreateCollectionReq.CollectionSchema schema = CreateCollectionReq.CollectionSchema.builder()
        .enableDynamicField(true)
        .build();
    schema.addField(AddFieldReq.builder()
            .fieldName("id")
            .dataType(io.milvus.v2.common.DataType.Int64)
            .isPrimaryKey(Boolean.TRUE)
            .autoID(false)
            .build());
    schema.addField(AddFieldReq.builder()
            .fieldName("bool")
            .dataType(DataType.Bool)
            .build());
    schema.addField(AddFieldReq.builder()
            .fieldName("int8")
            .dataType(DataType.Int8)
            .build());
    schema.addField(AddFieldReq.builder()
            .fieldName("int16")
            .dataType(DataType.Int16)
            .build());
    schema.addField(AddFieldReq.builder()
            .fieldName("int32")
            .dataType(DataType.Int32)
            .build());
    schema.addField(AddFieldReq.builder()
            .fieldName("int64")
            .dataType(DataType.Int64)
            .build());
    schema.addField(AddFieldReq.builder()
            .fieldName("float")
            .dataType(DataType.Float)
            .build());
    schema.addField(AddFieldReq.builder()
            .fieldName("double")
            .dataType(DataType.Double)
            .build());
    schema.addField(AddFieldReq.builder()
            .fieldName("varchar")
            .dataType(DataType.VarChar)
            .maxLength(512)
            .build());
    schema.addField(AddFieldReq.builder()
            .fieldName("json")
            .dataType(io.milvus.v2.common.DataType.JSON)
            .build());
    schema.addField(AddFieldReq.builder()
            .fieldName("array_int")
            .dataType(io.milvus.v2.common.DataType.Array)
            .maxCapacity(100)
            .elementType(io.milvus.v2.common.DataType.Int64)
            .build());
    schema.addField(AddFieldReq.builder()
            .fieldName("array_str")
            .dataType(io.milvus.v2.common.DataType.Array)
            .maxCapacity(100)
            .elementType(io.milvus.v2.common.DataType.VarChar)
            .maxLength(128)
            .build());
    schema.addField(AddFieldReq.builder()
            .fieldName("float_vector")
            .dataType(io.milvus.v2.common.DataType.FloatVector)
            .dimension(DIM)
            .build());
    schema.addField(AddFieldReq.builder()
            .fieldName("binary_vector")
            .dataType(io.milvus.v2.common.DataType.BinaryVector)
            .dimension(DIM)
            .build());
    schema.addField(AddFieldReq.builder()
            .fieldName("float16_vector")
            .dataType(io.milvus.v2.common.DataType.Float16Vector)
            .dimension(DIM)
            .build());
    schema.addField(AddFieldReq.builder()
            .fieldName("sparse_vector")
            .dataType(io.milvus.v2.common.DataType.SparseFloatVector)
            .build());
    
    return schema;
}
```

ä¸Šè¿°ä»£ç ä¸­çš„å­—æ®µè§£é‡Šå¦‚ä¸‹ï¼š 

- åä¸º `id` çš„å­—æ®µä¸ºä¸»é”®ï¼Œå…¶ `withAutoID` è®¾ç½®ä¸º `false`ï¼Œè¡¨æ˜åœ¨å¯¼å…¥æ•°æ®æ—¶ï¼Œå¾…æ’å…¥æ•°æ®ä¸­åº”è¯¥åŒ…å«ä¸»é”®ã€‚

- åä¸º `title_vector` çš„å­—æ®µä¸ºå‘é‡å­—æ®µï¼Œå…¶ `withDimension` è®¾ç½®ä¸º 768ï¼Œè¡¨æ˜å¾…æ’å…¥æ•°æ®å„æ¡è®°å½•ä¸­è¯¥å­—æ®µçš„å€¼éœ€ä¸ºä¸€ä¸ª 768 ç»´çš„å‘é‡ã€‚

- Schema å®šä¹‰ä¸­çš„ `withEnableDynamicField` è®¾ç½®ä¸º `true`ï¼Œè¡¨æ˜æ‚¨å¯ä»¥åœ¨å¾…æ’å…¥æ•°æ®ä¸­åŒ…å« Schema ä¸­æœªå®šä¹‰çš„å­—æ®µã€‚

</TabItem>

</Tabs>

åœ¨åˆ›å»º Schema åï¼Œå°±å¯ä»¥ç»§ç»­åˆ›å»ºç›®æ ‡ Collection äº†ã€‚

<Tabs groupId="code" defaultValue='python' values={[{"label":"Python","value":"python"},{"label":"Java","value":"java"}]}>
<TabItem value='python'>

```python
from pymilvus import MilvusClient

# 1. Set up a Milvus client
client = MilvusClient(
    uri=CLUSTER_ENDPOINT,
    token=API_KEY
)

# 2. Set index parameters
index_params = MilvusClient.prepare_index_params()

index_params.add_index(
    field_name="float_vector",
    index_type="AUTOINDEX",
    metric_type="IP"
)

index_params.add_index(
    field_name="binary_vector",
    index_type="AUTOINDEX",
    metric_type="HAMMING"
)

index_params.add_index(
    field_name="float16_vector",
    index_type="AUTOINDEX",
    metric_type="IP"
)

index_params.add_index(
    field_name="sparse_vector",
    index_type="AUTOINDEX",
    metric_type="IP"
)

# 3. Create collection
client.create_collection(
    collection_name=COLLECTION_NAME,
    schema=schema,
    index_params=index_params
)
```

</TabItem>

<TabItem value='java'>

```java
import com.google.common.collect.Lists;
import io.milvus.v2.client.ConnectConfig;
import io.milvus.v2.client.MilvusClientV2;
import io.milvus.v2.common.IndexParam;
import io.milvus.v2.service.collection.request.CreateCollectionReq;
import java.util.List;

// 1. Set up a Milvus client
MilvusClientV2 milvusClient = new MilvusClientV2(ConnectConfig.builder()
        .uri(CLUSTER_ENDPOINT)
        .token(API_KEY)
        .build());

// 2. Set index parameters
IndexParam floatVectorIndex = IndexParam.builder()
        .fieldName("float_vector")
        .indexType(IndexParam.IndexType.AUTOINDEX)
        .metricType(IndexParam.MetricType.IP)
        .build();

IndexParam binaryVectorIndex = IndexParam.builder()
        .fieldName("binary_vector")
        .indexType(IndexParam.IndexType.AUTOINDEX)
        .metricType(IndexParam.MetricType.HAMMING)
        .build();

IndexParam float16VectorIndex = IndexParam.builder()
        .fieldName("float16_vector")
        .indexType(IndexParam.IndexType.AUTOINDEX)
        .metricType(IndexParam.MetricType.IP)
        .build();

IndexParam sparseVectorIndex = IndexParam.builder()
        .fieldName("sparse_vector")
        .indexType(IndexParam.IndexType.AUTOINDEX)
        .metricType(IndexParam.MetricType.IP)
        .build();

List<IndexParam> indexParamList = Lists.newArrayList(
        floatVectorIndex,
        binaryVectorIndex,
        float16VectorIndex,
        sparseVectorIndex
);

// 3. Create collection
CreateCollectionReq.CollectionSchema schema = createSchema();
CreateCollectionReq request = CreateCollectionReq.builder()
        .collectionName(COLLECTION_NAME)
        .collectionSchema(schema)
        .indexParams(indexParamList)
        .build();
milvusClient.createCollection(request);
```

</TabItem>
</Tabs>

## å‡†å¤‡æºæ•°æ®{#prepare-source-data}

**BulkWriter** ä¼šå°†æ‚¨æä¾›çš„æ•°æ®è½¬æ¢æˆ JSONã€Parquet æˆ– NumPy æ–‡ä»¶ã€‚åœ¨ä¸‹é¢çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ª **RemoteBulkWriter** å¹¶ä½¿ç”¨è¯¥ **RemoteBulkWriter** å°†æ‚¨çš„æ•°æ®è½¬æ¢æˆä¸Šè¿°æ ¼å¼ã€‚

### åˆ›å»º RemoteBulkWriter{#create-remotebulkwriter}

å½“ Schema å‡†å¤‡å¥½åï¼Œå°±å¯ä»¥ä½¿ç”¨è¯¥ Schema åˆ›å»º **RemoteBulkWriter** äº†ã€‚ç”±äº **RemoteBulkWriter** éœ€è¦è®¿é—®æ‚¨çš„è¿œç¨‹å¯¹è±¡å­˜å‚¨æ¡¶ã€‚å› æ­¤ï¼Œæ‚¨éœ€è¦å…ˆè®¾ç½®å¥½è¿æ¥è¿œç¨‹å¯¹è±¡å­˜å‚¨æ¡¶çš„ **ConnectParam** å¯¹è±¡å¹¶åœ¨åˆ›å»º **RemoteBulkWriter** æ—¶å¼•ç”¨è¯¥å‚æ•°ã€‚

<Tabs groupId="code" defaultValue='python' values={[{"label":"Python","value":"python"},{"label":"Java","value":"java"}]}>
<TabItem value='python'>

```python
from pymilvus.bulk_writer import RemoteBulkWriter, BulkFileType
# Use `from pymilvus import RemoteBulkWriter, BulkFileType`
# if your pymilvus version is earlier than 2.4.2 

# Connections parameters to access the remote bucket
conn = RemoteBulkWriter.S3ConnectParam(
    # è…¾è®¯äº‘è¯·ä½¿ç”¨ "cos.ap-beijing-1.myqcloud.com"
    endpoint="oss-cn-hangzhou.aliyuncs.com",
    access_key=ACCESS_KEY,
    secret_key=SECRET_KEY,
    bucket_name=BUCKET_NAME, 
    secure=True
)
```

</TabItem>

<TabItem value='java'>

```java
import io.milvus.bulkwriter.connect.S3ConnectParam;
import io.milvus.bulkwriter.connect.StorageConnectParam;

// åˆ›å»ºä¸€ä¸ª RemoteBulkWriter.
StorageConnectParam storageConnectParam = S3ConnectParam.newBuilder()
        // è…¾è®¯äº‘è¯·ä½¿ç”¨ "cos.ap-beijing-1.myqcloud.com"
        .withEndpoint("oss-cn-hangzhou.aliyuncs.com") 
        .withBucketName(BUCKET_NAME)
        .withAccessKey(ACCESS_KEY)
        .withSecretKey(SECRET_KEY)
        .build();
```

</TabItem>
</Tabs>

<Admonition type="info" icon="ğŸ“˜" title="è¯´æ˜">

<p>å‚æ•° <strong>endpoint</strong> å†³å®šäº†ç”Ÿæˆæ–‡ä»¶çš„è¾“å‡ºè·¯å¾„ã€‚è¯·åŠ¡å¿…ç¡®ä¿æ‚¨çš„ç›®æ ‡ Collection æ‰€åœ¨åœ°åŸŸä¸æ‚¨çš„è¿œç¨‹å¯¹è±¡å­˜å‚¨æ¡¶æ‰€åœ¨åœ°åŸŸä¸€è‡´ã€‚</p>
<p>å…³äºé˜¿é‡Œäº‘ä¸‹ OSS Region å’Œ Endpoint å¯¹ç…§å…³ç³»ï¼Œå¯<a href="https://help.aliyun.com/zh/oss/user-guide/regions-and-endpoints">å‚è€ƒæ­¤æ–‡</a>ã€‚</p>
<p>å…³äºè…¾è®¯äº‘ä¸‹ OSS Region å’Œ Endpoint å¯¹ç…§å…³ç³»ï¼Œå¯<a href="https://cloud.tencent.com/document/product/436/6224">å‚è€ƒæ­¤æ–‡</a>ã€‚</p>

</Admonition>

ç„¶åï¼Œåœ¨åˆ›å»º **RemoteBulkWriter** æ—¶éœ€è¦å¼•ç”¨ä¸Šè¿° **ConnectParam** å¯¹è±¡ã€‚

<Tabs groupId="code" defaultValue='python' values={[{"label":"Python","value":"python"},{"label":"Java","value":"java"}]}>

<TabItem value='python'>

```python
writer = RemoteBulkWriter(
    schema=schema, # ç›®æ ‡ Collection çš„ Schema
    remote_path="/", # ç›¸å¯¹äºè¿œç¨‹å¯¹è±¡å­˜å‚¨æ¡¶æ ¹ç›®å½•çš„è¾“å‡ºè·¯å¾„
    segment_size=512*1024*1024, # åŸå§‹æ•°æ®åˆ†æ®µå¤§å°
    connect_param=conn, # è¿œç¨‹å¯¹è±¡å­˜å‚¨æ¡¶çš„è¿æ¥å‚æ•°
    file_type=BulkFileType.PARQUET # è¾“å‡ºæ–‡ä»¶ç±»å‹.
)

# æ”¯æŒçš„è¾“å‡ºæ–‡ä»¶ç±»å‹:
# - BulkFileType.JSON_RB, 
# - BulkFileType.NPY, and 
# - BulkFileType.PARQUET
```

ä¸Šè¿°ä»£ç å°†ç”Ÿæˆ JSON æ ¼å¼çš„æ–‡ä»¶å¹¶å°†å…¶ä¸Šä¼ åˆ°æŒ‡å®šæ¡¶çš„æ ¹ç›®å½•ä¸‹ã€‚

- `remote_path="/"`

    æ­¤å‚æ•°å†³å®šäº†ç”Ÿæˆæ–‡ä»¶åœ¨è¿œç¨‹å¯¹è±¡å­˜å‚¨æ¡¶ä¸­çš„è¾“å‡ºè·¯å¾„ã€‚

    å°†å…¶è®¾ç½®ä¸º `"/"` ä¼šä½¿ **RemoteBulkWriter** å°†ç”Ÿæˆçš„æ–‡ä»¶æ”¾å…¥è¿œç¨‹å¯¹è±¡å­˜å‚¨æ¡¶çš„æ ¹ç›®å½•ä¸‹ã€‚è‹¥éœ€æ”¾å…¥å…¶å®ƒè·¯å¾„ï¼Œè¯·ä½¿ç”¨ç›¸å¯¹äºæ¡¶æ ¹ç›®å½•çš„ç›¸å¯¹è·¯å¾„ã€‚

- `file_type=BulkFileType.PARQUET`

    æ­¤å‚æ•°å†³å®šäº†ç”Ÿæˆæ–‡ä»¶çš„æ–‡ä»¶ç±»å‹ã€‚å¯é€‰å€¼å¦‚ä¸‹ï¼š

    - **BulkFileType.JSON_RB**

    - **BulkFileType.PARQUET**

    - **BulkFileType.NPY**

- `segment_size=512*1024*1024`

    æ­¤å‚æ•°å†³å®šäº† **BulkWriter** å¦‚ä½•å¯¹åŸå§‹æ•°æ®è¿›è¡Œåˆ†æ®µã€‚è¯¥å‚æ•°é»˜è®¤å€¼ä¸º 512 MB (512 * 1024 * 1024)ã€‚å¦‚æœæ‚¨çš„æ•°æ®é›†åŒ…å«æ•°æ®é‡è¾ƒå¤§æ—¶ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨è¯¥å‚æ•°å¯¹æ•°æ®è¿›è¡Œåˆç†åˆ†æ®µã€‚

</TabItem>

<TabItem value='java'>

```java
import io.milvus.bulkwriter.RemoteBulkWriter;
import io.milvus.bulkwriter.RemoteBulkWriterParam;
import io.milvus.bulkwriter.common.clientenum.BulkFileType;

RemoteBulkWriterParam remoteBulkWriterParam = RemoteBulkWriterParam.newBuilder()
        .withCollectionSchema(schema)
        .withRemotePath("/")
        .withChunkSize(512 * 1024 * 1024)
        .withConnectParam(storageConnectParam)
        .withFileType(BulkFileType.PARQUET)
        .build();
        
@SuppressWarnings("resource")
RemoteBulkWriter remoteBulkWriter = new RemoteBulkWriter(remoteBulkWriterParam);

// Possible file types:
// - BulkFileType.PARQUET
```

ä¸Šè¿°ä»£ç å°†ç”Ÿæˆ JSON æ ¼å¼çš„æ–‡ä»¶å¹¶å°†å…¶ä¸Šä¼ åˆ°æŒ‡å®šæ¡¶çš„æ ¹ç›®å½•ä¸‹ã€‚

- `withRemotePath("/")`

    æ­¤å‚æ•°å†³å®šäº†ç”Ÿæˆæ–‡ä»¶åœ¨è¿œç¨‹å¯¹è±¡å­˜å‚¨æ¡¶ä¸­çš„è¾“å‡ºè·¯å¾„ã€‚

    å°†å…¶è®¾ç½®ä¸º `"/"` ä¼šä½¿ **RemoteBulkWriter** å°†ç”Ÿæˆçš„æ–‡ä»¶æ”¾å…¥è¿œç¨‹å¯¹è±¡å­˜å‚¨æ¡¶çš„æ ¹ç›®å½•ä¸‹ã€‚è‹¥éœ€æ”¾å…¥å…¶å®ƒè·¯å¾„ï¼Œè¯·ä½¿ç”¨ç›¸å¯¹äºæ¡¶æ ¹ç›®å½•çš„ç›¸å¯¹è·¯å¾„ã€‚

- `withFileType(BulkFileType.PARQUET)`

    æ­¤å‚æ•°å†³å®šäº†ç”Ÿæˆæ–‡ä»¶çš„æ–‡ä»¶ç±»å‹ã€‚å½“å‰ **PARQUET** ä¸ºå”¯ä¸€æ”¯æŒçš„æ ¼å¼ã€‚

- `withChunkSize(512*1024*1024)`

    æ­¤å‚æ•°å†³å®šäº† **BulkWriter** å¦‚ä½•å¯¹åŸå§‹æ•°æ®è¿›è¡Œåˆ†æ®µã€‚è¯¥å‚æ•°é»˜è®¤å€¼ä¸º 512 MB (512 * 1024 * 1024)ã€‚å¦‚æœæ‚¨çš„æ•°æ®é›†åŒ…å«æ•°æ®é‡è¾ƒå¤§æ—¶ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨è¯¥æ–¹æ³•å¯¹æ•°æ®è¿›è¡Œåˆç†åˆ†æ®µã€‚

</TabItem>

</Tabs>

### ä½¿ç”¨ Writer{#use-the-writer}

**Writer** å¯¹è±¡æœ‰ä¸¤ä¸ªæ–¹æ³•ï¼šä¸€ä¸ªæ˜¯å°†åŸå§‹æ•°æ®ä»¥è¡Œçš„å½¢å¼æ·»åŠ åˆ°ç¼“å­˜ä¸­ï¼Œå¦ä¸€ä¸ªåˆ™æ˜¯å°†ç¼“å­˜ä¸­çš„æ•°æ®å†™å…¥åˆ°è¿œç¨‹å¯¹è±¡å­˜å‚¨æ¡¶ä¸­ã€‚

æ‚¨å¯ä»¥å‚è€ƒå¦‚ä¸‹ä»£ç å°†åŸå§‹æ•°æ®ä»¥è¡Œçš„å½¢å¼æ·»åŠ åˆ°ç¼“å­˜ä¸­ã€‚

<Tabs groupId="code" defaultValue='python' values={[{"label":"Python","value":"python"},{"label":"Java","value":"java"}]}>
<TabItem value='python'>

```python
import random, string, json
import numpy as np
import tensorflow as tf

def generate_random_str(length=5):
    letters = string.ascii_uppercase
    digits = string.digits
    
    return ''.join(random.choices(letters + digits, k=length))

# optional input for binary vector:
# 1. list of int such as [1, 0, 1, 1, 0, 0, 1, 0]
# 2. numpy array of uint8
def gen_binary_vector(to_numpy_arr):
    raw_vector = [random.randint(0, 1) for i in range(DIM)]
    if to_numpy_arr:
        return np.packbits(raw_vector, axis=-1)
    return raw_vector

# optional input for float vector:
# 1. list of float such as [0.56, 1.859, 6.55, 9.45]
# 2. numpy array of float32
def gen_float_vector(to_numpy_arr):
    raw_vector = [random.random() for _ in range(DIM)]
    if to_numpy_arr:
        return np.array(raw_vector, dtype="float32")
    return raw_vector

# # optional input for bfloat16 vector:
# # 1. list of float such as [0.56, 1.859, 6.55, 9.45]
# # 2. numpy array of bfloat16
# def gen_bf16_vector(to_numpy_arr):
#     raw_vector = [random.random() for _ in range(DIM)]
#     if to_numpy_arr:
#         return tf.cast(raw_vector, dtype=tf.bfloat16).numpy()
#     return raw_vector

# optional input for float16 vector:
# 1. list of float such as [0.56, 1.859, 6.55, 9.45]
# 2. numpy array of float16
def gen_fp16_vector(to_numpy_arr):
    raw_vector = [random.random() for _ in range(DIM)]
    if to_numpy_arr:
        return np.array(raw_vector, dtype=np.float16)
    return raw_vector

# optional input for sparse vector:
# only accepts dict like {2: 13.23, 45: 0.54} or {"indices": [1, 2], "values": [0.1, 0.2]}
# note: no need to sort the keys
def gen_sparse_vector(pair_dict: bool):
    raw_vector = {}
    dim = random.randint(2, 20)
    if pair_dict:
        raw_vector["indices"] = [i for i in range(dim)]
        raw_vector["values"] = [random.random() for _ in range(dim)]
    else:
        for i in range(dim):
            raw_vector[i] = random.random()
    return raw_vector

for i in range(2000):
    writer.append_row({
        "id": np.int64(i),
        "bool": True if i % 3 == 0 else False,
        "int8": np.int8(i%128),
        "int16": np.int16(i%1000),
        "int32": np.int32(i%100000),
        "int64": np.int64(i),
        "float": np.float32(i/3),
        "double": np.float64(i/7),
        "varchar": f"varchar_{i}",
        "json": json.dumps({"dummy": i, "ok": f"name_{i}"}),
        "array_str": np.array([f"str_{k}" for k in range(5)], np.dtype("str")),
        "array_int": np.array([k for k in range(10)], np.dtype("int64")),
        "float_vector": gen_float_vector(True),
        "binary_vector": gen_binary_vector(True),
        "float16_vector": gen_fp16_vector(True),
        # "bfloat16_vector": gen_bf16_vector(True),
        "sparse_vector": gen_sparse_vector(True),
        f"dynamic_{i}": i,
    })
    if (i+1)%1000 == 0:
        writer.commit()
        print('committed')

print(writer.batch_files)
```

</TabItem>

<TabItem value='java'>

```java
import com.google.gson.JsonObject;
import io.milvus.bulkwriter.RemoteBulkWriter;
import io.milvus.bulkwriter.RemoteBulkWriterParam;
import io.milvus.bulkwriter.common.clientenum.BulkFileType;
import io.milvus.bulkwriter.connect.S3ConnectParam;
import io.milvus.bulkwriter.connect.StorageConnectParam;
import io.milvus.common.utils.Float16Utils;
import io.milvus.v2.service.collection.request.CreateCollectionReq;

import java.io.IOException;
import java.nio.ByteBuffer;
import java.util.ArrayList;
import java.util.List;
import java.util.Random;
import java.util.SortedMap;
import java.util.TreeMap;

private static byte[] genBinaryVector() {
    Random ran = new Random();
    int byteCount = DIM / 8;
    ByteBuffer vector = ByteBuffer.allocate(byteCount);
    for (int i = 0; i < byteCount; ++i) {
        vector.put((byte) ran.nextInt(Byte.MAX_VALUE));
    }
    return vector.array();
}

private static List<Float> genFloatVector() {
    Random ran = new Random();
    List<Float> vector = new ArrayList<>();
    for (int i = 0; i < DIM; ++i) {
        vector.add(ran.nextFloat());
    }
    return vector;
}

private static byte[] genFloat16Vector() {
    List<Float> originalVector = genFloatVector();
    return Float16Utils.f32VectorToFp16Buffer(originalVector).array();
}

private static SortedMap<Long, Float> genSparseVector() {
    Random ran = new Random();
    SortedMap<Long, Float> sparse = new TreeMap<>();
    int dim = ran.nextInt(18) + 2; // [2, 20)
    for (int i = 0; i < dim; ++i) {
        sparse.put((long)ran.nextInt(1000000), ran.nextFloat());
    }
    return sparse;
}

private static List<String> genStringArray(int length) {
    List<String> arr = new ArrayList<>();
    for (int i = 0; i < length; i++) {
        arr.add("str_" + i);
    }
    return arr;
}

private static List<Long> genIntArray(int length) {
    List<Long> arr = new ArrayList<>();
    for (long i = 0; i < length; i++) {
        arr.add(i);
    }
    return arr;
}

private static RemoteBulkWriter createRemoteBulkWriter(CreateCollectionReq.CollectionSchema collectionSchema) throws IOException {
    StorageConnectParam connectParam = S3ConnectParam.newBuilder()
            .withEndpoint(STORAGE_ENDPOINT)
            .withBucketName(BUCKET_NAME)
            .withAccessKey(ACCESS_KEY)
            .withSecretKey(SECRET_KEY)
            .build();
    RemoteBulkWriterParam bulkWriterParam = RemoteBulkWriterParam.newBuilder()
            .withCollectionSchema(collectionSchema)
            .withRemotePath("/")
            .withChunkSize(1024 * 1024 * 1024)
            .withConnectParam(connectParam)
            .withFileType(BulkFileType.PARQUET)
            .build();
    return new RemoteBulkWriter(bulkWriterParam);
}

private static List<List<String>> uploadData() throws Exception {
    CreateCollectionReq.CollectionSchema collectionSchema = createSchema();
    try (RemoteBulkWriter remoteBulkWriter = createRemoteBulkWriter(collectionSchema)) {
        for (int i = 0; i < 2000; ++i) {
            JsonObject rowObject = new JsonObject();

            rowObject.addProperty("id", i);
            rowObject.addProperty("bool", i % 3 == 0);
            rowObject.addProperty("int8", i % 128);
            rowObject.addProperty("int16", i % 1000);
            rowObject.addProperty("int32", i % 100000);
            rowObject.addProperty("int64", i);
            rowObject.addProperty("float", i / 3);
            rowObject.addProperty("double", i / 7);
            rowObject.addProperty("varchar", "varchar_" + i);
            rowObject.addProperty("json", String.format("{\"dummy\": %s, \"ok\": \"name_%s\"}", i, i));
            rowObject.add("array_str", GSON_INSTANCE.toJsonTree(genStringArray(5)));
            rowObject.add("array_int", GSON_INSTANCE.toJsonTree(genIntArray(10)));
            rowObject.add("float_vector", GSON_INSTANCE.toJsonTree(genFloatVector()));
            rowObject.add("binary_vector", GSON_INSTANCE.toJsonTree(genBinaryVector()));
            rowObject.add("float16_vector", GSON_INSTANCE.toJsonTree(genFloat16Vector()));
            rowObject.add("sparse_vector", GSON_INSTANCE.toJsonTree(genSparseVector()));
            rowObject.addProperty("dynamic", "dynamic_" + i);

            remoteBulkWriter.appendRow(rowObject);

            if ((i+1)%1000 == 0) {
                remoteBulkWriter.commit(false);
            }
        }

        List<List<String>> batchFiles = remoteBulkWriter.getBatchFiles();
        System.out.println(batchFiles);
        return batchFiles;
    } catch (Exception e) {
        throw e;
    }
}

public static void main(String[] args) throws Exception {
    List<List<String>> batchFiles = uploadData();
}
```

</TabItem>
</Tabs>

å¦‚ä¸Šè¿°ä»£ç æ‰€ç¤ºï¼Œ**accept_row()** æ–¹æ³•æ¥æ”¶ä¸€ä¸ªå­—å…¸ã€‚è¯¥å­—å…¸ä»¥é”®å€¼å¯¹çš„å½¢å¼è¡¨ç¤ºä¸€æ¡æ•°æ®ã€‚

éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¯¥å­—å…¸éœ€è¦åŒ…å«æ‰€æœ‰åœ¨ Schema ä¸­å®šä¹‰äº†çš„å­—æ®µã€‚å¦‚æœ Schema ä¸­è¿˜å¼€å¯äº†åŠ¨æ€å­—æ®µï¼Œè¯¥å­—å…¸è¿˜å…è®¸æºå¸¦ Schema ä¸­æœªå®šä¹‰çš„å­—æ®µã€‚å…·ä½“å†…å®¹ï¼Œå¯å‚è€ƒ[ä½¿ç”¨ BulkWriter](./use-bulkwriter)ã€‚

æ‚¨è¿˜éœ€è¦è°ƒç”¨ **commit()** æ–¹æ³•æ‰èƒ½å°†ç¼“å­˜ä¸­çš„æ•°æ®å†™å…¥åˆ°è¿œç¨‹å¯¹è±¡å­˜å‚¨æ¡¶ä¸­ã€‚

<Tabs groupId="code" defaultValue='python' values={[{"label":"Python","value":"python"},{"label":"Java","value":"java"}]}>
<TabItem value='python'>

```python
writer.commit()
```

</TabItem>

<TabItem value='java'>

```java
remoteBulkWriter.commit(false);
```

</TabItem>
</Tabs>

è‡³æ­¤ï¼ŒBulkWriter å°†åŸå§‹æ•°æ®æŒ‰æ‚¨çš„è¦æ±‚è½¬æ¢æˆ Zilliz Cloud å¯è¯†åˆ«çš„æ ¼å¼å¹¶å°†å…¶å­˜æ”¾åˆ°æŒ‡å®šçš„è¿œç¨‹å¯¹è±¡å­˜å‚¨æ¡¶ä¸­ã€‚æ‚¨å¯ä»¥è¿è¡Œå¦‚ä¸‹æŒ‡ä»¤æŸ¥çœ‹è¾“å…¥è·¯å¾„ã€‚

<Tabs groupId="code" defaultValue='python' values={[{"label":"Python","value":"python"},{"label":"Java","value":"java"}]}>
<TabItem value='python'>

```python
print(writer.data_path)

# /5868ba87-743e-4d9e-8fa6-e07b39229425
```

</TabItem>

<TabItem value='java'>

```java
import java.util.List;

List<List<String>> batchFiles = remoteBulkWriter.getBatchFiles();
System.out.println(batchFiles);

// [["/5868ba87-743e-4d9e-8fa6-e07b39229425/1.parquet"]]
```

</TabItem>
</Tabs>

<Admonition type="info" icon="ğŸ“˜" title="è¯´æ˜">

<p><strong>BulkWriter</strong> ç”Ÿæˆä¸€ä¸ª UUIDï¼Œå¹¶ä½¿ç”¨è¯¥ UUID åœ¨æŒ‡å®šçš„è¾“å…¥è·¯å¾„ä¸‹åˆ›å»ºä¸€ä¸ªå­è·¯å¾„ï¼Œç„¶åå°†ç”Ÿæˆçš„æ–‡ä»¶æ”¾åœ¨åˆ›å»ºçš„å­è·¯å¾„ä¸‹ã€‚</p>

</Admonition>

æ›´å¤šå†…å®¹ï¼Œå¯å‚è€ƒ[ä½¿ç”¨ BulkWriter](./use-bulkwriter)ã€‚

## å¯¼å…¥æºæ•°æ®{#import-prepared-data}

åœ¨æ­¤æ­¥éª¤ä¹‹å‰ï¼Œè¯·å†æ¬¡ç¡®è®¤æ‚¨å‡†å¤‡çš„æ•°æ®å·²ç»æ­£ç¡®ä¸Šä¼ åˆ°æ‚¨çš„å­˜å‚¨æ¡¶ä¸­ã€‚

### åˆ›å»ºæ‰¹é‡å¯¼å…¥ä»»åŠ¡{#start-importing}

æ‚¨å¯ä»¥ä½¿ç”¨ bulk_import() å‡½æ•°å¯¼å…¥å‡†å¤‡å¥½çš„æºæ•°æ®ã€‚

<Tabs groupId="code" defaultValue='python' values={[{"label":"Python","value":"python"},{"label":"Java","value":"java"}]}>
<TabItem value='python'>

```python
from pymilvus.bulk_writer import bulk_import

# Publicly accessible URL for the prepared data in the remote bucket
object_url = "s3://{0}/{1}/".format(BUCKET_NAME, str(writer.data_path)[1:])
# Change `s3` to `gs` for Google Cloud Storage

resp = bulk_import(
    api_key=API_KEY,
    url=CLOUD_API_ENDPOINT,
    cluster_id=CLUSTER_ID,
    collection_name=COLLECTION_NAME,
    object_url=object_url,
    access_key=ACCESS_KEY,
    secret_key=SECRET_KEY
)

job_id = resp.json()['data']['jobId']
print(job_id)

# job-0103f039ccdq9aip1xd4rf
```

</TabItem>

<TabItem value='java'>

```java
import io.milvus.bulkwriter.request.import_.CloudImportRequest;
import io.milvus.bulkwriter.BulkImport;

// Insert the data into the collection
String prefix = batchFiles.get(0).get(0).split("/")[0];
String OBJECT_URL = String.format("s3://%s/%s/", BUCKET_NAME, prefix);

CloudImportRequest cloudImportRequest = CloudImportRequest.builder()
        .apiKey(API_KEY)
        .clusterId(CLUSTER_ID)
        .collectionName(COLLECTION_NAME)
        .objectUrl(OBJECT_URL)
        .accessKey(ACCESS_KEY)
        .secretKey(SECRET_KEY)
        .build();
String bulkImportResult = BulkImport.bulkImport(CLOUD_API_ENDPOINT, cloudImportRequest);

JsonObject bulkImportObject = new Gson().fromJson(bulkImportResult, JsonObject.class);
String jobId = bulkImportObject.getAsJsonObject("data").get("jobId").getAsString();
System.out.println(jobId);
// job-0103f039ccdq9aip1xd4rf
```

</TabItem>
</Tabs>

<Admonition type="info" icon="ğŸ“˜" title="Notes">

<p>å‚æ•° <strong>object_url</strong> éœ€ä¸ºè¿œç¨‹å¯¹è±¡å­˜å‚¨æ¡¶ä¸­ä¸€ä¸ªåˆæ³•çš„æ–‡ä»¶æˆ–ç›®å½•ã€‚åœ¨ä¸Šè¿°ä»£ç ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº† <strong>format()</strong> æ–¹æ³•å°†æ¡¶åç§°å’Œ Writer è¿”å›çš„è·¯å¾„æ‹¼æ¥æˆä¸€ä¸ªåˆæ³•çš„ç›®å½•è·¯å¾„ã€‚</p>
<p>å¦‚éœ€äº†è§£æ›´å¤šä¿¡æ¯ï¼Œå¯å‚è€ƒ <a href="https://help.aliyun.com/zh/oss/user-guide/oss-domain-names">OSS è®¿é—®åŸŸåä½¿ç”¨è§„åˆ™</a> ï¼ˆé˜¿é‡Œäº‘ï¼‰æˆ–<a href="https://cloud.tencent.com/document/product/436/6224">åœ°åŸŸå’Œè®¿é—®åŸŸå</a>ï¼ˆè…¾è®¯äº‘ï¼‰ã€‚</p>

</Admonition>

### æ£€æŸ¥ä»»åŠ¡è¿›åº¦{#check-task-progress}

å¦‚ä¸‹ä»£ç æ¯ 5 ç§’é’Ÿæ£€æŸ¥ä¸€æ¬¡ä»»åŠ¡è¿›åº¦ï¼Œå¹¶æ‰“å°è¿›åº¦ä¿¡æ¯ã€‚

<Tabs groupId="code" defaultValue='python' values={[{"label":"Python","value":"python"},{"label":"Java","value":"java"}]}>
<TabItem value='python'>

```python
import time
from pymilvus import get_import_progress

job_id = res.json()['data']['jobId']

res = get_import_progress(
    api_key=API_KEY,
    url=CLOUD_API_ENDPOINT,
    cluster_id=CLUSTER_ID,  # Zilliz Cloud cluster ID, like "in01-xxxxxxxxxxxxxxx"
    job_id=job_id,
)

print(res.json()["data"]["progress"])

# check the bulk-import progress
while res.json()["data"]["progress"] < 100:
    time.sleep(5)

    res = get_import_progress(
        # highlight-next-line
        url=CLOUD_API_ENDPOINT,
        api_key=API_KEY,
        job_id=job_id,
        cluster_id=CLUSTER_ID
    )
    
    print(res.json()["data"]["progress"])

# 0   -- import progress 0%
# 49  -- import progress 49%
# 100 -- import finished
```

</TabItem>

<TabItem value='java'>

```java
while (true) {
    System.out.println("Wait 5 second to check bulkInsert job state...");
    TimeUnit.SECONDS.sleep(5);
    
    CloudDescribeImportRequest request = CloudDescribeImportRequest.builder()
        .apiKey(API_KEY)
        .clusterId(CLUSTER_ID)
        .jobId(jobId)
        .build();
    String getImportProgressResult = BulkImport.getImportProgress(CLOUD_API_ENDPOINT, request);
    JsonObject getImportProgressObject = GSON_INSTANCE.fromJson(getImportProgressResult, JsonObject.class);
    String importProgressState = getImportProgressObject.getAsJsonObject("data").get("state").getAsString();
    String progress = getImportProgressObject.getAsJsonObject("data").get("progress").getAsString();

    if ("Failed".equals(importProgressState)) {
        String reason = getImportProgressObject.getAsJsonObject("data").get("reason").getAsString();
        System.out.printf("The job %s failed, reason: %s%n", jobId, reason);
        break;
    } else if ("Completed".equals(importProgressState)) {
        System.out.printf("The job %s completed%n", jobId);
        break;
    } else {
        System.out.printf("The job %s is running, state:%s progress:%s%n", jobId, importProgressState, progress);
    }
}

// The job job-01f36d8fd67u94avjfnxi0 is running, state:Importing progress:0
// The job job-01f36d8fd67u94avjfnxi0 is running, state:Importing progress:49
// The job 0f7fe853-d93e-4681-99f2-4719c63585cc completed.
```

</TabItem>
</Tabs>

<Admonition type="info" icon="ğŸ“˜" title="è¯´æ˜">

<p>ä¸Šè¿°ä»£ç ä¸­ï¼Œå‚æ•° <strong>url</strong> ä¸º Zilliz Cloud RESTful API çš„æœåŠ¡å™¨è·¯å¾„ï¼Œå…¶å–å€¼é¡»ä¸ç›®æ ‡ Collection æ‰€åœ¨äº‘åœ°åŸŸä¿æŒä¸€è‡´ã€‚</p>

</Admonition>

æ‚¨è¿˜å¯ä»¥åˆ—å‡ºæ‰€æœ‰æ‰¹é‡å¯¼å…¥ä»»åŠ¡ã€‚

<Tabs groupId="code" defaultValue='python' values={[{"label":"Python","value":"python"},{"label":"Java","value":"java"}]}>
<TabItem value='python'>

```python
from pymilvus import list_import_jobs

res = list_import_jobs(
    api_key=API_KEY,
    # highlight-next-line
    url=CLOUD_API_ENDPOINT,
    cluster_id=CLUSTER_ID  # Zilliz Cloud cluster ID, like "in01-xxxxxxxxxxxxxxx"
)

print(res.json())

# {
#     "code": 0,
#     "data": {
#         "records": [
#             {
#                 "collectionName": "zero_to_hero",
#                 "jobId": "job-01f36d8fd67u94avjfnxi0",
#                 "state": "Completed"
#             }
#         ],
#         "count": 1,
#         "currentPage": 1,
#         "pageSize": 10
#     }
# }
```

</TabItem>

<TabItem value='java'>

```java
CloudListImportJobsRequest listImportJobsRequest = CloudListImportJobsRequest.builder()
        .apiKey(API_KEY)
        .clusterId(CLUSTER_ID) // Zilliz Cloud cluster ID, like "in01-xxxxxxxxxxxxxxx"
        .build();
String listImportJobsResult = BulkImport.listImportJobs(CLOUD_API_ENDPOINT, listImportJobsRequest);
System.out.println(listImportJobsResult);
```

</TabItem>
</Tabs>

## å°ç»“{#recaps}

æœ¬æ•™ç¨‹æ¶µç›–äº†æ•°æ®å¯¼å…¥çš„å…¨æµç¨‹ã€‚ä¸‹é¢æ˜¯ä¸€äº›åœ¨è¿›è¡Œæ•°æ®å¯¼å…¥æ—¶éœ€è¦éµå¾ªçš„ä¸€äº›åŸåˆ™ï¼š

- ä»”ç»†åˆ†ææ‚¨çš„åŸå§‹æ•°æ®ï¼Œä»¥ä¾¿æ›´å¥½åœ°å®Œæˆç›®æ ‡ Collection çš„ Schema è®¾è®¡ã€‚

- åœ¨å¯¼å…¥æ•°æ®å‰ï¼Œè¯·ç¡®ä¿ Zilliz Cloud é›†ç¾¤å’Œ BulkWriter çš„è¾“å‡ºè·¯å¾„æ‰€åœ¨å¯¹è±¡å­˜å‚¨æ¡¶ç”±åŒä¸€å®¶äº‘æœåŠ¡æä¾›å•†æ‰˜ç®¡ã€‚

- åœ¨ä½¿ç”¨ **BulkWriter** æ—¶ï¼Œè¯·æ³¨æ„ï¼š

    - åœ¨ **append_row()** ä¸­ï¼ŒåŠ¡å¿…ç¡®ä¿å‚æ•°å­—å…¸ä¸­åŒ…å«æ‰€æœ‰ Schema ä¸­å®šä¹‰çš„å­—æ®µã€‚å¦‚æœ Schema è¿˜å…è®¸åŠ¨æ€å­—æ®µï¼Œæ‚¨è¿˜å¯ä»¥åœ¨è¯¥å­—å…¸ä¸­åŒ…å«æœªåœ¨ Schema ä¸­å®šä¹‰çš„å­—æ®µã€‚

    - åœ¨å°†æ‰€æœ‰æ•°æ®æ·»åŠ åˆ°ç¼“å­˜ä¸­åï¼Œè¿˜éœ€è¦è°ƒç”¨ **commit()** æ–¹æ³•æ‰èƒ½å°†è½¬æ¢å¥½çš„æ•°æ®ä¸Šä¼ åˆ°æŒ‡å®šçš„è¿œç¨‹å¯¹è±¡å­˜å‚¨æ¡¶ä¸­ã€‚

- åœ¨ä½¿ç”¨ **bulk_import()** å‡½æ•°æ—¶ï¼Œæ‚¨éœ€è¦å°†æ¡¶åç§°ã€æ¡¶ä¸­æ–‡ä»¶æˆ–ç›®å½•çš„å¤–éƒ¨è®¿é—®åŸŸåï¼Œä»¥åŠ Writer è¿”å›çš„è·¯å¾„æ‹¼æ¥åœ¨ä¸€èµ·åˆæˆä¸€ä¸ªåˆæ³•çš„ **object_url**ã€‚

