---
slug: /import-data-via-sdks
beta: FALSE
notebook: 05_use_local-bulk-writer.ipynb,06_use_remote-bulk-writer.ipynb,07_use_bulk_import.ipynb
token: Xv4awWJZpiKoJjkPTlic98Mindc
sidebar_position: 3
---

import Admonition from '@theme/Admonition';


# é€šè¿‡ SDK å¯¼å…¥

æœ¬èŠ‚å°†å¸®åŠ©ä½ äº†è§£å¦‚ä½•ä½¿ç”¨ SDK çš„ BulkWriter å’Œ BulkImport API å‘ Collection ä¸­å¯¼å…¥æ•°æ®ã€‚

å¦å¤–ï¼Œæ‚¨è¿˜å¯ä»¥å‚è€ƒæˆ‘ä»¬çš„[å¿«é€Ÿå…¥é—¨æŒ‡å—](./data-import-zero-to-hero)ã€‚å…¶ä¸­åŒ…å«äº†æ•°æ®å‡†å¤‡å’Œæ•°æ®å¯¼å…¥ä¸¤ä¸ªéƒ¨åˆ†çš„å†…å®¹ã€‚

## å®‰è£…ä¾èµ–{#install-denpendencies}

åœ¨å‘½ä»¤è¡Œä¸­è¿è¡Œå¦‚ä¸‹å‘½ä»¤å®‰è£… pymilvus å’Œ minio æˆ–å°†å®ƒä»¬å‡çº§åˆ°æœ€æ–°ç‰ˆæœ¬ã€‚

```shell
python3 -m pip install --upgrade pymilvus minio
```

### æ£€æŸ¥å·²å‡†å¤‡æ•°æ®{#check-prepared-data}

åœ¨æ‚¨[ä½¿ç”¨ BulkWriter](./use-bulkwriter) å®Œæˆæ•°æ®å‡†å¤‡å·¥ä½œåï¼Œä½ ä¼šè·å¾—ä¸€ä¸ªè·¯å¾„ï¼ŒæŒ‡å‘å‡†å¤‡å¥½çš„æ•°æ®æ–‡ä»¶ã€‚æ‚¨å¯ä»¥ä½¿ç”¨å¦‚ä¸‹ä»£ç æ¥æ£€æŸ¥è¿™äº›æ•°æ®æ–‡ä»¶ã€‚

```python
from minio import Minio

# Third-party constants
YOUR_ACCESS_KEY = "YOUR_ACCESS_KEY"
YOUR_SECRET_KEY = "YOUR_SECRET_KEY"
YOUR_BUCKET_NAME = "YOUR_BUCKET_NAME"
YOUR_REMOTE_PATH = "YOUR_REMOTE_PATH"

client = Minio(
    endpoint="storage.googleapis.com", # use 's3.amazonaws.com' for AWS S3
    access_key=YOUR_ACCESS_KEY,
    secret_key=YOUR_SECRET_KEY,
    secure=True
)

objects = client.list_objects(
    bucket_name=YOUR_BUCKET_NAME,
    prefix=YOUR_REMOTE_PATH,
    recursive=True
)

print([obj.object_name for obj in objects])

# Output
#
# [
#     "folder/1/claps.npy",
#     "folder/1/id.npy",
#     "folder/1/link.npy",
#     "folder/1/publication.npy",
#     "folder/1/reading_time.npy",
#     "folder/1/responses.npy",
#     "folder/1/title.npy",
#     "folder/1/vector.npy"
# ]

```

### åˆ›å»º Collection å¹¶å¯¼å…¥æ•°æ®{#create-collection-and-import-data}

å‡†å¤‡å¥½æ•°æ®æ–‡ä»¶åï¼Œæ‚¨éœ€è¦å…ˆè¿æ¥åˆ° Zilliz Cloud é›†ç¾¤ï¼Œæ ¹æ®æ•°æ®é›†çš„æ ¼å¼åˆ›å»ºç›¸åº”çš„ Collectionï¼Œå¹¶ä»å­˜å‚¨æ¡¶ä¸­å¯¼å…¥æ•°æ®æ–‡ä»¶ã€‚

å¯¹äºå¦‚ä½•åœ¨ Zilliz Cloud æ§åˆ¶å°ä¸Šè·å–ç›¸å…³ä¿¡æ¯ï¼Œå¯ä»¥å‚è€ƒ [Zilliz Cloud æ§åˆ¶å°](./on-zilliz-cloud-console)ã€‚

<Admonition type="info" icon="ğŸ“˜" title="è¯´æ˜">

<p>ç”±äº Zilliz Cloud ç›®å‰ä¸æ”¯æŒè·¨äº‘æ•°æ®ä¼ è¾“ï¼Œæ‚¨çš„ Zilliz Cloud é›†ç¾¤å’Œæ•°æ®é›†éœ€ä½äºåŒä¸€å…¬å…±äº‘å¹³å°ä¸Šã€‚</p>

</Admonition>

```python
from pymilvus import MilvusClient, DataType

# set up your collection

## Zilliz Cloud constants
CLUSTER_ENDPOINT = "YOUR_CLUSTER_ENDPOINT"
CLUSTER_TOKEN = "YOUR_CLUSTER_TOKEN"
COLLECTION_NAME = "medium_articles"
API_KEY = "YOUR_CLUSTER_TOKEN"
CLUSTER_ID = "YOUR_CLUSTER_ID"

## Third-party constants
YOUR_OBJECT_URL = "YOUR_OBJECT_URL"

# create a milvus client
client = MilvusClient(
    uri=CLUSTER_ENDPOINT,
    token=CLUSTER_TOKEN
)

# prepare schema
schema = MilvusClient.create_schema(
    auto_id=False,
    enable_dynamic_schema=False
)

schema.add_field(field_name="id", datatype=DataType.INT64, is_primary=True)
schema.add_field(field_name="title", datatype=DataType.VARCHAR, max_length=512)
schema.add_field(field_name="vector", datatype=DataType.FLOAT_VECTOR, dim=768)
schema.add_field(field_name="link", datatype=DataType.VARCHAR, max_length=512)
schema.add_field(field_name="reading_time", datatype=DataType.INT64)
schema.add_field(field_name="publication", datatype=DataType.VARCHAR, max_length=512)
schema.add_field(field_name="claps", datatype=DataType.INT64)
schema.add_field(field_name="responses", datatype=DataType.INT64)

# prepare index parameters
index_params = MilvusClient.prepare_index_params()

index_params.add_index(
    field_name="vector",
    index_type="AUTOINDEX",
    metric_type="L2"
)

client.create_collection(
    collection_name="customized_setup",
    schema=schema,
    index_params=index_params
)# }
```

## å¯¼å…¥æ•°æ®{#import-data}

åœ¨å¾…å¯¼å…¥æ•°æ®å’Œ Collection éƒ½å‡†å¤‡å°±ç»ªåï¼Œå¯ä»¥ä½¿ç”¨å¦‚ä¸‹è„šæœ¬å°†æ•°æ®å¯¼å…¥ Collectionã€‚

```python
from pymilvus import bulk_import

# Bulk-import your data from the prepared data files

res = bulk_import(
    url=f"controller.api.{CLOUD_REGION}.zillizcloud.com",
    api_key=API_KEY,
    object_url=OBJECT_URL,
    access_key=ACCESS_KEY,
    secret_key=SECRET_KEY,
    cluster_id=CLUSTER_ID,
    collection_name=COLLECTION_NAME
)

print(res.json())

# Output
#
# {
#     "code": 200,
#     "data": {
#         "jobId": "9d0bc230-6b99-4739-a872-0b91cfe2515a"
#     }
# }
```

### æŸ¥çœ‹æ‰¹é‡å¯¼å…¥è¿›åº¦{#check-import-progress}

å¯é€šè¿‡ä»¥ä¸‹ä»£ç æŸ¥çœ‹æ‰¹é‡å¯¼å…¥è¿›åº¦ï¼š

```python
from pymilvus import get_import_progress

job_id = res.json()['data']['jobId']
res = get_import_progress(
    url=f"controller.api.{CLOUD_REGION}.zillizcloud.com",
    api_key=API_KEY,
    job_id=job_id,
    cluster_id=CLUSTER_ID
)

# check the bulk-import progress

while res.json()["data"]["readyPercentage"] < 1:
    time.sleep(5)

    res = get_import_progress(
        url=f"controller.api.{CLOUD_REGION}.zillizcloud.com",
        api_key=API_KEY,
        job_id=job_id,
        cluster_id=CLUSTER_ID
    )

print(res.json())

# Output
#
# {
#     "code": 200,
#     "data": {
#         "collectionName": "medium_articles",
#         "fileName": "folder/1/",
#         "fileSize": 26571700,
#         "readyPercentage": 1,
#         "completeTime": "2023-10-28T06:51:49Z",
#         "errorMessage": null,
#         "jobId": "9d0bc230-6b99-4739-a872-0b91cfe2515a",
#         "details": [
#             {
#                 "fileName": "folder/1/",
#                 "fileSize": 26571700,
#                 "readyPercentage": 1,
#                 "completeTime": "2023-10-28T06:51:49Z",
#                 "errorMessage": null
#             }
#         ]
#     }
# }
```

### åˆ—å‡ºæ‰€æœ‰æ‰¹é‡å¯¼å…¥ä»»åŠ¡{#list-all-import-jobs}

æ‚¨è¿˜å¯ä»¥è°ƒç”¨ ListImportJobs API æ¥äº†è§£å…¶å®ƒæ‰¹é‡å¯¼å…¥ä»»åŠ¡çš„è¿è¡Œæƒ…å†µï¼š

```python
from pymilvus import list_import_jobs

# list bulk-import jobs

res = list_import_jobs(
    url=f"controller.api.{CLOUD_REGION}.zillizcloud.com",
    api_key=API_KEY,
    cluster_id=CLUSTER_ID,
    page_size=10,
    current_page=1,
)

print(res.json())

# Output
#
# {
#     "code": 200,
#     "data": {
#         "tasks": [
#             {
#                 "collectionName": "medium_articles",
#                 "jobId": "9d0bc230-6b99-4739-a872-0b91cfe2515a",
#                 "state": "ImportCompleted"
#             },
#             {
#                 "collectionName": "medium_articles",
#                 "jobId": "53632e6c-c078-4476-b840-10c4793d9c08",
#                 "state": "ImportCompleted"
#             },
#         ],
#         "count": 2,
#         "currentPage": 1,
#         "pageSize": 10
#     }
# }
```

## æ¨èé˜…è¯»{#related-topics}

- [é€šè¿‡ Web æ§åˆ¶å°å¯¼å…¥](./import-data-on-web-ui)

- [é€šè¿‡ RESTful API å¯¼å…¥](./import-data-via-restful-api)

- [ä½¿ç”¨ BulkWriter å¯¼å…¥](./prepare-source-data) 

