---
title: "æœ€ä½³å®è·µï¼šå¦‚ä½•é€‰æ‹©åˆé€‚çš„ Analyzer | BYOC"
slug: /choose-the-right-analyzer-for-your-use-case
sidebar_label: "æœ€ä½³å®è·µ"
beta: PUBLIC
added_since: FALSE
last_modified: FALSE
deprecate_since: FALSE
notebook: FALSE
description: "æœ€ä½³å®è·µï¼šå¦‚ä½•é€‰æ‹©åˆé€‚çš„ Analyzer | BYOC"
type: origin
token: Sotxw9TeRiM6U1k2aQ7cc3SUn9d
sidebar_position: 6
keywords: 
  - å‘é‡æ•°æ®åº“
  - zilliz
  - milvus
  - å¤§æ¨¡å‹å‘é‡æ•°æ®åº“
  - schema
  - æ ‡é‡å­—æ®µ
  - åˆ†æå™¨
  - analyzer
  - tokenizer
  - filter
  - æ•™ç¨‹ï¼Œæœ€ä½³å®è·µ

---

import Admonition from '@theme/Admonition';


import Supademo from '@site/src/components/Supademo';

# æœ€ä½³å®è·µï¼šå¦‚ä½•é€‰æ‹©åˆé€‚çš„ Analyzer

<Admonition type="info" icon="ğŸ“˜" title="è¯´æ˜">

<p>æœ¬æŒ‡å—ä¾§é‡äº Analyzer é€‰æ‹©çš„å®é™…å†³ç­–æ–¹æ³•ã€‚å…³äº Analyzer ç»„ä»¶çš„æŠ€æœ¯ç»†èŠ‚ä»¥åŠå¦‚ä½•æ·»åŠ  Analyzer å‚æ•°ï¼Œè¯·å‚è€ƒ <a href="./analyzer-overview">Analyzer æ¦‚è¿°</a>ã€‚</p>

</Admonition>

## å¿«é€Ÿäº†è§£ Analyzer\{#quick-concept-how-analyzers-work}

åœ¨ Zilliz Cloud ä¸­ï¼ŒAnalyzer ä¼šå¤„ç†å­˜å‚¨åœ¨å­—æ®µä¸­çš„æ–‡æœ¬ï¼Œä½¿å…¶å¯ç”¨äº [Full Text Search](./full-text-search)ï¼ˆBM25ï¼‰ã€[Phrase Match](./phrase-match) æˆ– [Text Match](./text-match)ã€‚å¯ä»¥å°†å®ƒè§†ä½œä¸€ä¸ªæ–‡æœ¬å¤„ç†å™¨ï¼ŒæŠŠåŸå§‹å†…å®¹è½¬åŒ–ä¸ºå¯æœç´¢çš„ tokenã€‚ä¸€ä¸ª Analyzer çš„å·¥ä½œåˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼š

![HZhjw5hTuhfOIebOsnOcmy8Hnuf](/img/HZhjw5hTuhfOIebOsnOcmy8Hnuf.png)

1. **åˆ†è¯ (Tokenization, å¿…éœ€)**ï¼šé€šè¿‡ tokenizer å°†è¿ç»­çš„æ–‡æœ¬æ‹†åˆ†ä¸ºç‹¬ç«‹ä¸”æœ‰æ„ä¹‰çš„ tokenã€‚ä¸åŒè¯­è¨€å’Œå†…å®¹ç±»å‹çš„åˆ†è¯æ–¹å¼å·®å¼‚å¾ˆå¤§ã€‚

1. **Token è¿‡æ»¤ (å¯é€‰)**ï¼šåœ¨åˆ†è¯ååº”ç”¨è¿‡æ»¤å™¨ï¼Œç”¨äºä¿®æ”¹ã€åˆ é™¤æˆ–ä¼˜åŒ– tokenã€‚ä¾‹å¦‚ï¼Œå°†æ‰€æœ‰ token è½¬æ¢ä¸ºå°å†™ã€å»æ‰å¸¸è§åœç”¨è¯ï¼Œæˆ–å°†å•è¯è¿˜åŸä¸ºè¯æ ¹ã€‚

**ç¤ºä¾‹**ï¼š

```plaintext
è¾“å…¥: "Hello World!" 
       1. åˆ†è¯ â†’ ["Hello", "World", "!"]
       2. å°å†™ä¸æ ‡ç‚¹è¿‡æ»¤ â†’ ["hello", "world"]
```

## ä¸ºä»€ä¹ˆé€‰æ‹©åˆé€‚çš„ Analyzer å¾ˆé‡è¦\{#why-the-choice-of-analyzer-matters}

é€‰æ‹©ä¸å½“çš„ Analyzer å¯èƒ½å¯¼è‡´ç›¸å…³æ–‡æ¡£æ— æ³•è¢«æœç´¢åˆ°ï¼Œæˆ–è¿”å›æ— å…³ç»“æœã€‚

ä¸‹è¡¨æ€»ç»“äº†å› é”™è¯¯é€‰æ‹© Analyzer è€Œå¯¼è‡´çš„å¸¸è§é—®é¢˜ï¼Œå¹¶æä¾›äº†å¯æ“ä½œçš„è§£å†³æ–¹æ¡ˆï¼š

<table>
   <tr>
     <th><p><strong>é—®é¢˜</strong></p></th>
     <th><p><strong>ç—‡çŠ¶</strong></p></th>
     <th><p><strong>ç¤ºä¾‹</strong></p></th>
     <th><p><strong>é”™è¯¯åŸå› </strong></p></th>
     <th><p><strong>è§£å†³æ–¹æ¡ˆ</strong></p></th>
   </tr>
   <tr>
     <td><p><strong>è¿‡åº¦åˆ†è¯</strong></p></td>
     <td><p>æŠ€æœ¯æœ¯è¯­ã€æ ‡è¯†ç¬¦æˆ– URL æœç´¢ä¸åˆ°</p></td>
     <td><ul><li><p><code>"user_id"</code> â†’ <code>['user','id']</code></p></li><li><p><code>"C++"</code> â†’ <code>['c']</code></p></li></ul></td>
     <td><p><a href="./standard-tokenizer">standard</a> Analyzer</p></td>
     <td><p>ä½¿ç”¨ <a href="./whitespace-tokenizer">whitespace</a> tokenizer å¹¶ç»“åˆ <a href="./alphanumonly-filter">alphanumonly</a> è¿‡æ»¤å™¨</p></td>
   </tr>
   <tr>
     <td><p><strong>åˆ†è¯ä¸è¶³</strong></p></td>
     <td><p>å¤šè¯çŸ­è¯­çš„ä¸€éƒ¨åˆ†æ— æ³•åŒ¹é…å®Œæ•´çŸ­è¯­</p></td>
     <td><p><code>"state-of-the-art"</code> â†’ <code>['state-of-the-art']</code></p></td>
     <td><p>ä½¿ç”¨ <a href="./whitespace-tokenizer">whitespace</a> tokenizer</p></td>
     <td><p>ä½¿ç”¨ <a href="./standard-tokenizer">standard</a> tokenizerï¼Œå¹¶é…åˆ <a href="./regex-filter">regex</a> è¿‡æ»¤å™¨</p></td>
   </tr>
   <tr>
     <td><p><strong>è¯­è¨€ä¸åŒ¹é…</strong></p></td>
     <td><p>ç‰¹å®šè¯­è¨€æœç´¢æ— æ•ˆæˆ–ç»“æœå¼‚å¸¸</p></td>
     <td><p><code>"æœºå™¨å­¦ä¹ "</code> â†’ <code>['æœºå™¨å­¦ä¹ ']</code></p></td>
     <td><p>ä½¿ç”¨ <a href="./english-analyzer">english</a> Analyzer</p></td>
     <td><p>ä½¿ç”¨ç‰¹å®šè¯­è¨€çš„ Analyzerï¼Œå¦‚ <a href="./chinese-analyzer">Chinese</a></p></td>
   </tr>
</table>

## ç¬¬ä¸€æ­¥ï¼šä½ æ˜¯å¦éœ€è¦é€‰æ‹© Analyzerï¼Ÿ\{#first-question-do-you-need-to-choose-an-analyzer}

å¦‚æœæœªæŒ‡å®š Analyzerï¼Œåœ¨ä½¿ç”¨å…¨æ–‡æ£€ç´¢ç­‰åŠŸèƒ½æ—¶ï¼ŒZilliz Cloud ä¼šè‡ªåŠ¨åº”ç”¨ **[standard** ](./standard-analyzer)[Analyzer](./standard-analyzer)ã€‚

å®ƒä¼šï¼š

- æŒ‰ç©ºæ ¼å’Œæ ‡ç‚¹åˆ†è¯

- å°†æ‰€æœ‰ token è½¬ä¸ºå°å†™

- ç§»é™¤å†…ç½®çš„å¸¸è§è‹±æ–‡åœç”¨è¯å’Œå¤§å¤šæ•°æ ‡ç‚¹

**ç¤ºä¾‹**ï¼š

```plaintext
è¾“å…¥:  "The Milvus vector database is built for scale!"
è¾“å‡º: ['the', 'milvus', 'vector', 'database', 'is', 'built', 'scale']
```

## ç¬¬äºŒæ­¥ï¼šåˆ¤æ–­ Standard Analyzer æ˜¯å¦æ»¡è¶³ä¸šåŠ¡éœ€æ±‚\{#step-2-check-if-the-standard-analyzer-meets-your-needs}

ä½¿ç”¨ä¸‹è¡¨å¿«é€Ÿåˆ¤æ–­é»˜è®¤çš„ [Standard Analyzer](./standard-analyzer) æ˜¯å¦æ»¡è¶³ä½ çš„éœ€æ±‚ã€‚å¦‚æœä¸æ»¡è¶³ï¼Œä½ éœ€è¦[é€šè¿‡ä¸åŒè·¯å¾„](./choose-the-right-analyzer-for-your-use-case#step-3-choose-your-path)é€‰æ‹©å…¶ä»– Analyzerã€‚

<table>
   <tr>
     <th><p><strong>å†…å®¹</strong></p></th>
     <th><p><strong>standard Analyzer æ˜¯å¦åˆé€‚ï¼Ÿ</strong></p></th>
     <th><p><strong>åŸå› </strong></p></th>
     <th><p><strong>éœ€è¦ä»€ä¹ˆ</strong></p></th>
   </tr>
   <tr>
     <td><p>è‹±æ–‡åšå®¢</p></td>
     <td><p>âœ… æ˜¯</p></td>
     <td><p>é»˜è®¤å³å¯</p></td>
     <td><p>ä½¿ç”¨é»˜è®¤</p></td>
   </tr>
   <tr>
     <td><p>ä¸­æ–‡æ–‡æ¡£</p></td>
     <td><p>âŒ å¦</p></td>
     <td><p>ä¸­æ–‡æ— ç©ºæ ¼ï¼Œæ•´æ®µè§†ä½œå• token</p></td>
     <td><p>ä½¿ç”¨å†…ç½® <a href="./chinese-analyzer">chinese</a> Analyzer</p></td>
   </tr>
   <tr>
     <td><p>æŠ€æœ¯æ–‡æ¡£</p></td>
     <td><p>âŒ å¦</p></td>
     <td><p>ç¬¦å·ä¸¢å¤±ï¼Œå¦‚ C++ â†’ C</p></td>
     <td><p>ä½¿ç”¨ <a href="./whitespace-tokenizer">whitespace</a> tokenizer + <a href="./alphanumonly-filter">alphanumonly</a> filter</p></td>
   </tr>
   <tr>
     <td><p>æ³•è¯­/è¥¿ç­ç‰™è¯­</p></td>
     <td><p>âš ï¸ å¯èƒ½</p></td>
     <td><p>cafÃ© ä¸ cafe ä¸åŒ¹é…</p></td>
     <td><p>ä½¿ç”¨ <a href="./ascii-folding-filter">asciifolding</a> filter</p></td>
   </tr>
   <tr>
     <td><p>å¤šè¯­è¨€æˆ–æœªçŸ¥è¯­è¨€</p></td>
     <td><p>âŒ å¦</p></td>
     <td><p>standard æ— æ³•å¤„ç†ä¸åŒå­—ç¬¦é›†</p></td>
     <td><p>ä½¿ç”¨ <a href="./icu-tokenizer">icu</a> tokenizer æˆ–å¤šè¯­è¨€æ–¹æ¡ˆ</p></td>
   </tr>
</table>

## ç¬¬ä¸‰æ­¥ï¼šé€šè¿‡ä¸åŒè·¯å¾„é€‰æ‹© Analyzer\{#step-3-choose-your-path}

å¦‚æœé»˜è®¤çš„æ ‡å‡†åˆ†æå™¨æ— æ³•æ»¡è¶³éœ€æ±‚ï¼Œè¯·é€‰æ‹©ä»¥ä¸‹ä¸¤ç§è·¯å¾„ä¹‹ä¸€ï¼š

- **è·¯å¾„ A**ï¼šä½¿ç”¨å†…ç½® Analyzerï¼ˆå¼€ç®±å³ç”¨çš„è¯­è¨€ä¸“ç”¨ Analyzerï¼‰

- **è·¯å¾„ B**ï¼šåˆ›å»ºè‡ªå®šä¹‰ Analyzerï¼ˆæ‰‹åŠ¨å®šä¹‰ Tokenizer å’Œä¸€ç»„ Filterï¼‰

### è·¯å¾„ Aï¼šä½¿ç”¨å†…ç½® Analyzer\{#path-a-use-built-in-analyzers}

å†…ç½® Analyzer æ˜¯é¢„é…ç½®æ–¹æ¡ˆï¼Œé€‚åˆå¸¸è§è¯­è¨€ã€‚

#### å¯é€‰å†…ç½® Analyzer\{#available-built-in-analyzers}

<table>
   <tr>
     <th><p><strong>Analyzer</strong></p></th>
     <th><p><strong>è¯­è¨€æ”¯æŒ</strong></p></th>
     <th><p><strong>ç»„ä»¶</strong></p></th>
     <th><p><strong>è¯´æ˜</strong></p></th>
   </tr>
   <tr>
     <td><p><a href="./standard-analyzer">standard</a></p></td>
     <td><p>è‹±è¯­/æ³•è¯­/è¥¿ç­ç‰™è¯­ç­‰</p></td>
     <td><ul><li><p>Tokenizer: <code>standard</code></p></li><li><p>Filters: <code>lowercase</code></p></li></ul></td>
     <td><p>é€šç”¨æ–¹æ¡ˆ</p></td>
   </tr>
   <tr>
     <td><p><a href="./english-analyzer">english</a></p></td>
     <td><p>è‹±è¯­</p></td>
     <td><ul><li><p>Tokenizer: <code>standard</code></p></li><li><p>Filters: <code>lowercase</code>, <code>stemmer</code>, <code>stop</code></p></li></ul></td>
     <td><p>è‹±è¯­ä¸“ç”¨ï¼Œæ¨è</p></td>
   </tr>
   <tr>
     <td><p><a href="./chinese-analyzer">chinese</a></p></td>
     <td><p>ä¸­æ–‡</p></td>
     <td><ul><li><p>Tokenizer: <code>jieba</code></p></li><li><p>Filters: <code>cnalphanumonly</code></p></li></ul></td>
     <td><p>é»˜è®¤ç®€ä½“å­—å…¸</p></td>
   </tr>
</table>

#### ç¤ºä¾‹\{#implementation-example}

```python
# Using built-in English analyzer
analyzer_params = {
    "type": "english"
}

# Applying analyzer config to target VARCHAR field in your collection schema
schema.add_field(
    field_name='text',
    datatype=DataType.VARCHAR,
    max_length=200,
    enable_analyzer=True,
    # highlight-next-line
    analyzer_params=analyzer_params,
)
```

### è·¯å¾„ Bï¼šåˆ›å»ºè‡ªå®šä¹‰ Analyzer\{#path-b-create-a-custom-analyzer}

å½“å†…ç½®é€‰é¡¹ä¸è¶³æ—¶ï¼Œå¯ä»¥é€šè¿‡ **tokenizer + filter** è‡ªç”±ç»„åˆã€‚

#### æ­¥éª¤ 1ï¼šé€‰æ‹© tokenizer\{#step-1-select-the-tokenizer-based-on-language}

æ ¹æ®è¯­è¨€é€‰æ‹©åˆé€‚çš„ tokenizerï¼š

##### è¥¿æ–¹è¯­è¨€\{#western-languages}

å¯¹äºé€šè¿‡ç©ºæ ¼åˆ†éš”çš„è¯­è¨€ï¼Œæœ‰ä»¥ä¸‹é€‰æ‹©ï¼š

<table>
   <tr>
     <th><p>Tokenizer</p></th>
     <th><p>å·¥ä½œåŸç†</p></th>
     <th><p>é€‚ç”¨åœºæ™¯</p></th>
     <th><p>ç¤ºä¾‹</p></th>
   </tr>
   <tr>
     <td><p><a href="./standard-tokenizer"><code>standard</code></a></p></td>
     <td><p>åŸºäºç©ºæ ¼å’Œæ ‡ç‚¹æ‹†åˆ†æ–‡æœ¬</p></td>
     <td><p>é€šç”¨æ–‡æœ¬ï¼ŒåŒ…å«æ··åˆæ ‡ç‚¹çš„å†…å®¹</p></td>
     <td><ul><li><p>è¾“å…¥: <code>"Hello, world! Visit example.com"</code></p></li><li><p>è¾“å‡º: <code>['Hello', 'world', 'Visit', 'example', 'com']</code></p></li></ul></td>
   </tr>
   <tr>
     <td><p><a href="./whitespace-tokenizer"><code>whitespace</code></a></p></td>
     <td><p>ä»…åŸºäºç©ºæ ¼å­—ç¬¦æ‹†åˆ†</p></td>
     <td><p>å·²é¢„å¤„ç†çš„å†…å®¹ï¼Œç”¨æˆ·è‡ªå®šä¹‰æ ¼å¼çš„æ–‡æœ¬</p></td>
     <td><ul><li><p>è¾“å…¥: <code>"user_id = get_user_data()"</code></p></li><li><p>è¾“å‡º: <code>['user_id', '=', 'get_user_data()']</code></p></li></ul></td>
   </tr>
</table>

##### ä¸œäºšè¯­è¨€\{#east-asian-languages}

åŸºäºè¯å…¸çš„è¯­è¨€éœ€è¦ä¸“ç”¨çš„ tokenizer æ‰èƒ½è¿›è¡Œæ­£ç¡®çš„åˆ†è¯ï¼š

##### ä¸­æ–‡\{#chinese}

<table>
   <tr>
     <th><p>Tokenizer</p></th>
     <th><p>å·¥ä½œåŸç†</p></th>
     <th><p>é€‚ç”¨åœºæ™¯</p></th>
     <th><p>ç¤ºä¾‹</p></th>
   </tr>
   <tr>
     <td><p><a href="./jieba-tokenizer"><code>jieba</code></a></p></td>
     <td><p>åŸºäºä¸­æ–‡è¯å…¸çš„åˆ†è¯ï¼Œç»“åˆæ™ºèƒ½ç®—æ³•</p></td>
     <td><p>æ¨èç”¨äºä¸­æ–‡å†…å®¹â€”â€”ç»“åˆè¯å…¸ä¸æ™ºèƒ½ç®—æ³•ï¼Œä¸“ä¸ºä¸­æ–‡è®¾è®¡</p></td>
     <td><ul><li><p>è¾“å…¥: <code>"æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯"</code></p></li><li><p>è¾“å‡º: <code>['æœºå™¨', 'å­¦ä¹ ', 'æ˜¯', 'äººå·¥', 'æ™ºèƒ½', 'äººå·¥æ™ºèƒ½', 'çš„', 'ä¸€ä¸ª', 'åˆ†æ”¯']</code></p></li></ul></td>
   </tr>
   <tr>
     <td><p><a href="./lindera-tokenizer"><code>lindera</code></a></p></td>
     <td><p>çº¯è¯å…¸é©±åŠ¨çš„ä¸­æ–‡å½¢æ€å­¦åˆ†æï¼ˆä½¿ç”¨ <a href="https://cc-cedict.org/wiki/">cc-cedict</a> è¯å…¸ï¼‰</p></td>
     <td><p>ä¸ºæ—¥éŸ©åˆ†è¯è®¾è®¡ï¼Œä¹Ÿå¯ç”¨äºåˆ†è¯ä¸­æ–‡ï¼Œä½†æ€§èƒ½ä¸å¦‚ jieba</p></td>
     <td><ul><li><p>è¾“å…¥: <code>"æœºå™¨å­¦ä¹ ç®—æ³•"</code></p></li><li><p>è¾“å‡º: <code>["æœºå™¨", "å­¦ä¹ ", "ç®—æ³•"]</code></p></li></ul></td>
   </tr>
</table>

##### æ—¥è¯­å’ŒéŸ©è¯­\{#japanese-and-korean}

<table>
   <tr>
     <th><p>Tokenizer</p></th>
     <th><p>å·¥ä½œåŸç†</p></th>
     <th><p>é€‚ç”¨åœºæ™¯</p></th>
     <th><p>ç¤ºä¾‹</p></th>
     <th><p>Examples</p></th>
   </tr>
   <tr>
     <td><p>Japanese</p></td>
     <td><p><a href="./lindera-tokenizer"><code>lindera</code></a></p></td>
     <td><p><a href="https://taku910.github.io/mecab/">ipadic</a> (é€šç”¨), <a href="https://github.com/neologd/mecab-ipadic-neologd">ipadic-neologd</a> (ç°ä»£è¯æ±‡), <a href="https://clrd.ninjal.ac.jp/unidic/">unidic</a> (å­¦æœ¯)</p></td>
     <td><p>å½¢æ€å­¦åˆ†æï¼Œæ”¯æŒä¸“æœ‰åè¯å¤„ç†</p></td>
     <td><ul><li><p>è¾“å…¥: <code>"æ±äº¬éƒ½æ¸‹è°·åŒº"</code></p></li><li><p>è¾“å‡º: <code>["æ±äº¬", "éƒ½", "æ¸‹è°·", "åŒº"]</code></p></li></ul></td>
   </tr>
   <tr>
     <td><p>Korean</p></td>
     <td><p><a href="./lindera-tokenizer"><code>lindera</code></a></p></td>
     <td><p><a href="https://bitbucket.org/eunjeon/mecab-ko-dic/src/master/">ko-dic</a></p></td>
     <td><p>éŸ©è¯­å½¢æ€å­¦åˆ†æ</p></td>
     <td><ul><li><p>è¾“å…¥: <code>"ì•ˆë…•í•˜ì„¸ìš”"</code></p></li><li><p>è¾“å‡º: <code>["ì•ˆë…•", "í•˜", "ì„¸ìš”"]</code></p></li></ul></td>
   </tr>
</table>

##### å¤šè¯­è¨€æˆ–æœªçŸ¥è¯­è¨€\{#multilingual-or-unknown-languages}

é€‚ç”¨äºæ–‡æ¡£ä¸­è¯­è¨€ä¸å¯é¢„æµ‹æˆ–æ··åˆçš„æƒ…å†µï¼š

<table>
   <tr>
     <th><p>Tokenizer</p></th>
     <th><p>å·¥ä½œåŸç†</p></th>
     <th><p>é€‚ç”¨åœºæ™¯</p></th>
     <th><p>ç¤ºä¾‹</p></th>
     <th><p>Examples</p></th>
   </tr>
   <tr>
     <td><p><a href="./icu-tokenizer"><code>icu</code></a></p></td>
     <td><p>åŸºäº Unicode çš„åˆ†è¯ï¼ˆICU - International Components for Unicodeï¼‰</p></td>
     <td><p>æ··åˆæ–‡å­—ã€æœªçŸ¥è¯­è¨€ï¼Œæˆ–åªéœ€ç®€å•åˆ†è¯æ—¶</p></td>
     <td><ul><li><p>è¾“å…¥: <code>"Hello ä¸–ç•Œ Ù…Ø±Ø­Ø¨Ø§"</code></p></li><li><p>è¾“å‡º: <code>['Hello', ' ', 'ä¸–ç•Œ', ' ', 'Ù…Ø±Ø­Ø¨Ø§']</code></p></li></ul></td>
     <td></td>
   </tr>
</table>

**icu çš„ä½¿ç”¨åœºæ™¯**ï¼š

- å†…å®¹åŒ…å«æ··åˆè¯­è¨€ï¼Œä¸”è¯­è¨€è¯†åˆ«ä¸å¯è¡Œã€‚

- ä¸å¸Œæœ›ä½¿ç”¨å¤šè¯­è¨€ Analyzer æˆ– language identifier å¸¦æ¥çš„é¢å¤–å¼€é”€ã€‚

- æ–‡æœ¬ä»¥æŸä¸€ä¸»è¯­è¨€ä¸ºä¸»ï¼Œå¤¹æ‚å°‘é‡å¤–è¯­å•è¯ï¼Œè¿™äº›å¤–è¯­å¯¹æ•´ä½“è¯­ä¹‰å½±å“ä¸å¤§ï¼ˆå¦‚è‹±æ–‡æ–‡æœ¬ä¸­å¶å°”å‡ºç°æ—¥è¯­/æ³•è¯­å“ç‰Œåæˆ–æŠ€æœ¯æœ¯è¯­ï¼‰ã€‚

**æ›¿ä»£æ–¹æ¡ˆ**ï¼šå¦‚æœéœ€è¦æ›´ç²¾ç¡®åœ°å¤„ç†å¤šè¯­è¨€å†…å®¹ï¼Œå»ºè®®ä½¿ç”¨ [å¤šè¯­è¨€ Analyzer](./multi-language-analyzers) æˆ– [Language Identifier](./language-identifier-tokenizer)ã€‚

#### æ­¥éª¤ 2ï¼šæ·»åŠ è¿‡æ»¤å™¨ä»¥æé«˜ç²¾åº¦\{#step-2-add-filters-for-precision}

åœ¨é€‰æ‹©å¥½ tokenizer ä¹‹åï¼Œæ ¹æ®ä½ çš„å…·ä½“æœç´¢éœ€æ±‚å’Œå†…å®¹ç‰¹æ€§åº”ç”¨è¿‡æ»¤å™¨ã€‚

##### å¸¸ç”¨è¿‡æ»¤å™¨\{#commonly-used-filters}

è¿™äº›è¿‡æ»¤å™¨åœ¨å¤§å¤šæ•°ä»¥ç©ºæ ¼åˆ†éš”çš„è¯­è¨€ï¼ˆè‹±è¯­ã€æ³•è¯­ã€å¾·è¯­ã€è¥¿ç­ç‰™è¯­ç­‰ï¼‰ä¸­è‡³å…³é‡è¦ï¼Œå¹¶èƒ½æ˜¾è‘—æå‡æœç´¢è´¨é‡ï¼š

<table>
   <tr>
     <th><p>Filter</p></th>
     <th><p>å·¥ä½œåŸç†</p></th>
     <th><p>ä½¿ç”¨åœºæ™¯</p></th>
     <th><p>ç¤ºä¾‹</p></th>
   </tr>
   <tr>
     <td><p><a href="./lowercase-filter"><code>lowercase</code></a></p></td>
     <td><p>å°†æ‰€æœ‰ token è½¬æ¢ä¸ºå°å†™</p></td>
     <td><p>é€šç”¨â€”â€”é€‚ç”¨äºæ‰€æœ‰åŒºåˆ†å¤§å°å†™çš„è¯­è¨€</p></td>
     <td><ul><li><p>è¾“å…¥: <code>["Apple", "iPhone"]</code></p></li><li><p>è¾“å‡º: <code>[['apple'], ['iphone']]</code></p></li></ul></td>
   </tr>
   <tr>
     <td><p><a href="./stemmer-filter"><code>stemmer</code></a></p></td>
     <td><p>å°†å•è¯è¿˜åŸä¸ºè¯æ ¹</p></td>
     <td><p>é€‚ç”¨äºæœ‰è¯å½¢å˜åŒ–çš„è¯­è¨€ï¼ˆè‹±è¯­ã€æ³•è¯­ã€å¾·è¯­ç­‰ï¼‰</p></td>
     <td><p>è‹±è¯­ç¤ºä¾‹ï¼š</p><ul><li><p>è¾“å…¥: <code>["running", "runs", "ran"]</code></p></li><li><p>è¾“å‡º: <code>[['run'], ['run'], ['ran']]</code></p></li></ul></td>
   </tr>
   <tr>
     <td><p><a href="./stop-filter"><code>stop</code></a></p></td>
     <td><p>ç§»é™¤å¸¸è§çš„æ— æ„ä¹‰è¯ï¼ˆåœç”¨è¯ï¼‰</p></td>
     <td><p>å¤§å¤šæ•°è¯­è¨€ï¼Œå°¤å…¶æ˜¯ç©ºæ ¼åˆ†éš”çš„è¯­è¨€</p></td>
     <td><ul><li><p>è¾“å…¥: <code>["the", "quick", "brown", "fox"]</code></p></li><li><p>è¾“å‡º: <code>[[], ['quick'], ['brown'], ['fox']]</code></p></li></ul></td>
   </tr>
</table>

<Admonition type="info" icon="ğŸ“˜" title="è¯´æ˜">

<p>å¯¹äºä¸œäºšè¯­è¨€ï¼ˆä¸­æ–‡ã€æ—¥è¯­ã€éŸ©è¯­ç­‰ï¼‰ï¼Œè¯·é‡ç‚¹ä½¿ç”¨è¯­è¨€ç‰¹å®šçš„è¿‡æ»¤å™¨ã€‚è¿™äº›è¯­è¨€çš„æ–‡æœ¬å¤„ç†æ–¹å¼ä¸åŒï¼Œé€šå¸¸ä¸éœ€è¦æˆ–æ— æ³•ä»è¯å¹²æå–ä¸­è·ç›Šã€‚</p>

</Admonition>

##### æ–‡æœ¬è§„èŒƒåŒ–è¿‡æ»¤å™¨\{#text-normalization-filters}

è¿™äº›è¿‡æ»¤å™¨ç”¨äºæ ‡å‡†åŒ–æ–‡æœ¬å·®å¼‚ï¼Œæé«˜åŒ¹é…ä¸€è‡´æ€§ï¼š

<table>
   <tr>
     <th><p>Filter</p></th>
     <th><p>å·¥ä½œåŸç†</p></th>
     <th><p>ä½¿ç”¨åœºæ™¯</p></th>
     <th><p>ç¤ºä¾‹</p></th>
   </tr>
   <tr>
     <td><p><a href="./ascii-folding-filter"><code>asciifolding</code></a></p></td>
     <td><p>å°†å¸¦é‡éŸ³ç¬¦çš„å­—ç¬¦è½¬æ¢ä¸º ASCII ç­‰æ•ˆå­—ç¬¦</p></td>
     <td><p>å›½é™…åŒ–å†…å®¹ã€ç”¨æˆ·ç”Ÿæˆå†…å®¹</p></td>
     <td><ul><li><p>è¾“å…¥: <code>["cafÃ©", "naÃ¯ve", "rÃ©sumÃ©"]</code></p></li><li><p>è¾“å‡º: <code>[['cafe'], ['naive'], ['resume']]</code></p></li></ul></td>
   </tr>
</table>

##### Token è¿‡æ»¤\{#token-filtering}

è¿™äº›è¿‡æ»¤å™¨æ§åˆ¶å“ªäº› token ä¼šè¢«ä¿ç•™ï¼Œé€šå¸¸åŸºäºå­—ç¬¦ç±»å‹æˆ–é•¿åº¦ï¼š

<table>
   <tr>
     <th><p>Filter</p></th>
     <th><p>å·¥ä½œåŸç†</p></th>
     <th><p>ä½¿ç”¨åœºæ™¯</p></th>
     <th><p>ç¤ºä¾‹</p></th>
   </tr>
   <tr>
     <td><p><a href="./remove-punct-filter"><code>removepunct</code></a></p></td>
     <td><p>ç§»é™¤å•ç‹¬å­˜åœ¨çš„æ ‡ç‚¹ token</p></td>
     <td><p>æ¸…ç† <code>jieba</code>ã€<code>lindera</code>ã€<code>icu</code> è¾“å‡ºä¸­çš„å•ç‹¬æ ‡ç‚¹</p></td>
     <td><ul><li><p>è¾“å…¥: <code>["Hello", "!", "world"]</code></p></li><li><p>è¾“å‡º: <code>[['Hello'], ['world']]</code></p></li></ul></td>
   </tr>
   <tr>
     <td><p><a href="./alphanumonly-filter"><code>alphanumonly</code></a></p></td>
     <td><p>ä»…ä¿ç•™å­—æ¯å’Œæ•°å­—</p></td>
     <td><p>æŠ€æœ¯ç±»å†…å®¹ã€å¹²å‡€çš„æ–‡æœ¬å¤„ç†</p></td>
     <td><ul><li><p>è¾“å…¥: <code>["user123", "test@email.com"]</code></p></li><li><p>è¾“å‡º: <code>[['user123'], ['test', 'email', 'com']]</code></p></li></ul></td>
   </tr>
   <tr>
     <td><p><a href="./length-filter"><code>length</code></a></p></td>
     <td><p>ç§»é™¤è¶…å‡ºæŒ‡å®šé•¿åº¦èŒƒå›´çš„ token</p></td>
     <td><p>è¿‡æ»¤å™ªå£°ï¼ˆå¦‚è¿‡é•¿çš„ tokenï¼‰</p></td>
     <td><ul><li><p>è¾“å…¥: <code>["a", "very", "extraordinarily"]</code></p></li><li><p>è¾“å‡º: <code>[['a'], ['very'], []]</code> (if <strong>max=10</strong>)</p></li></ul></td>
   </tr>
   <tr>
     <td><p><a href="./regex-filter"><code>regex</code></a></p></td>
     <td><p>åŸºäºè‡ªå®šä¹‰æ¨¡å¼çš„è¿‡æ»¤</p></td>
     <td><p>ç‰¹å®šé¢†åŸŸçš„ token éœ€æ±‚</p></td>
     <td><ul><li><p>è¾“å…¥: <code>["test123", "prod456"]</code></p></li><li><p>è¾“å‡º: <code>[[], ['prod456']]</code> (if <strong>expr="^prod"</strong>)</p></li></ul></td>
   </tr>
</table>

##### è¯­è¨€ç‰¹å®šè¿‡æ»¤å™¨\{#language-specific-filters}

<table>
   <tr>
     <th><p>Filter</p></th>
     <th><p>Language</p></th>
     <th><p>How It Works</p></th>
     <th><p>Examples</p></th>
   </tr>
   <tr>
     <td><p><a href="./decompounder-filter"><code>decompounder</code></a></p></td>
     <td><p>å¾·è¯­</p></td>
     <td><p>å°†å¤åˆè¯æ‹†åˆ†ä¸ºå¯æœç´¢çš„ç»„æˆéƒ¨åˆ†</p></td>
     <td><ul><li><p>è¾“å…¥: <code>["dampfschifffahrt"]</code></p></li><li><p>è¾“å‡º: <code>[['dampf', 'schiff', 'fahrt']]</code></p></li></ul></td>
   </tr>
   <tr>
     <td><p><a href="./cnalphanumonly-filter">cnalphanumonly</a></p></td>
     <td><p>ä¸­æ–‡</p></td>
     <td><p>ä¿ç•™ä¸­æ–‡å­—ç¬¦ + å­—æ¯æ•°å­—</p></td>
     <td><ul><li><p>è¾“å…¥: <code>["Hello", "ä¸–ç•Œ", "123", "!@#"]</code></p></li><li><p>è¾“å‡º: <code>[['Hello'], ['ä¸–ç•Œ'], ['123'], []]</code></p></li></ul></td>
   </tr>
   <tr>
     <td><p><a href="./cncharonly-filter"><code>cncharonly</code></a></p></td>
     <td><p>ä¸­æ–‡</p></td>
     <td><p>ä»…ä¿ç•™ä¸­æ–‡å­—ç¬¦</p></td>
     <td><ul><li><p>è¾“å…¥: <code>["Hello", "ä¸–ç•Œ", "123"]</code></p></li><li><p>è¾“å‡º: <code>[[], ['ä¸–ç•Œ'], []]</code></p></li></ul></td>
   </tr>
</table>

#### æ­¥éª¤ 3ï¼šç»„åˆå¹¶å®ç°\{#step-3-combine-and-implement}

è¦åˆ›å»ºè‡ªå®šä¹‰ Analyzerï¼Œéœ€è¦åœ¨ `analyzer_params` å­—å…¸ä¸­å®šä¹‰ tokenizer å’Œè¿‡æ»¤å™¨åˆ—è¡¨ã€‚
 è¿™äº›è¿‡æ»¤å™¨ä¼šæŒ‰ç…§å®šä¹‰çš„é¡ºåºä¾æ¬¡åº”ç”¨ã€‚

```python
# Example: A custom analyzer for technical content
analyzer_params = {
    "tokenizer": "whitespace",
    "filter": ["lowercase", "alphanumonly"]
}

# Applying analyzer config to target VARCHAR field in your collection schema
schema.add_field(
    field_name='text',
    datatype=DataType.VARCHAR,
    max_length=200,
    enable_analyzer=True,
    # highlight-next-line
    analyzer_params=analyzer_params,
)
```

#### æœ€ç»ˆæ­¥éª¤ï¼šä½¿ç”¨ run_analyzer è¿›è¡Œæµ‹è¯•\{#final-test-with-run_analyzer}

åœ¨å°†é…ç½®åº”ç”¨åˆ° Collection ä¹‹å‰ï¼ŒåŠ¡å¿…å…ˆéªŒè¯ï¼š

```python
# Sample text to analyze
sample_text = "The Milvus vector database is built for scale!"

# Run analyzer with the defined configuration
result = client.run_analyzer(sample_text, analyzer_params)
print("Analyzer output:", result)
```

**éœ€è¦æ£€æŸ¥çš„å¸¸è§é—®é¢˜**

- **è¿‡åº¦åˆ†è¯**ï¼šæŠ€æœ¯æœ¯è¯­è¢«é”™è¯¯æ‹†åˆ†

- **åˆ†è¯ä¸è¶³**ï¼šçŸ­è¯­æœªè¢«æ­£ç¡®æ‹†åˆ†

- **token ä¸¢å¤±**ï¼šé‡è¦è¯è¢«è¿‡æ»¤æ‰

æ›´å¤šç”¨æ³•è¯·å‚è€ƒ [run_analyzer](https://milvus.io/api-reference/pymilvus/v2.6.x/MilvusClient/CollectionSchema/run_analyzer.md)ã€‚

## æŒ‰ä½¿ç”¨åœºæ™¯æ¨èçš„é…ç½®\{#recommended-configurations-by-use-case}

æœ¬èŠ‚ä¸ºåœ¨ Zilliz Cloud ä¸­ä½¿ç”¨ Analyzer æ—¶çš„å¸¸è§åœºæ™¯ï¼Œæä¾›æ¨èçš„ tokenizer ä¸ filter ç»„åˆã€‚è¯·é€‰æ‹©æœ€é€‚åˆä½ å†…å®¹ç±»å‹å’Œæœç´¢éœ€æ±‚çš„é…ç½®ã€‚

<Admonition type="info" icon="ğŸ“˜" title="è¯´æ˜">

<p>åœ¨å°† Analyzer åº”ç”¨åˆ° Collection å‰ï¼Œå»ºè®®å…ˆä½¿ç”¨ <strong>run_analyzer</strong> æ¥æµ‹è¯•å’ŒéªŒè¯æ–‡æœ¬åˆ†ææ•ˆæœã€‚</p>

</Admonition>

### è‹±æ–‡\{#english}

```json
analyzer_params = {
    "tokenizer": "standard",
    "filter": [
        "lowercase",
        {
            "type": "stemmer",
            "language": "english"
        },
        {
            "type": "stop",
            "stop_words": [
                "_english_"
            ]
        }
    ]
}
```

### ä¸­æ–‡\{#chinese}

```json
{
    "tokenizer": "jieba",
    "filter": ["cnalphanumonly"]
}
```

### é˜¿æ‹‰ä¼¯è¯­\{#arabic}

```python
{
    "tokenizer": "standard",
    "filter": [
        "lowercase",
        {
            "type": "stemmer",
            "language": "arabig"
        }
    ]
}
```

### å­ŸåŠ æ‹‰è¯­\{#bengali}

```python
{
    "tokenizer": "icu",
    "filter": ["lowercase", {
        "type": "stop",
        "stop_words": [<put stop words list here>]
    }]
}
```

### æ³•è¯­\{#french}

```json
{
    "tokenizer": "standard",
    "filter": [
        "lowercase",
        {
            "type": "stemmer",
            "language": "french"
        },
        {
            "type": "stop",
            "stop_words": [
                "_french_"
            ]
        }
    ]
}
```

### å¾·è¯­\{#german}

```json
{
    "tokenizer": {
        "type": "lindera",
        "dict_kind": "ipadic"
    },
    "filter": [
        "removepunct"
    ]
}
```

### å°åº¦è¯­\{#hindi}

```json
{
    "tokenizer": "icu",
    "filter": ["lowercase", {
        "type": "stop",
        "stop_words": [<put stop words list here>]
    }]
}
```

### æ—¥è¯­\{#japanese}

```json
{
    "tokenizer": {
        "type": "lindera",
        "dict_kind": "ipadic"
    },
    "filter": [
        "removepunct"
    ]
}
```

### è‘¡è„ç‰™è¯­\{#portuguese}

```json
{
    "tokenizer": "standard",
    "filter": [
        "lowercase",
        {
            "type": "stemmer",
            "language": "portuguese"
        },
        {
            "type": "stop",
            "stop_words": [
                "_portuguese_"
            ]
        }
    ]
}
```

### ä¿„è¯­\{#russian}

```json
{
    "tokenizer": "standard",
    "filter": [
        "lowercase",
        {
            "type": "stemmer",
            "language": "russian"
        },
        {
            "type": "stop",
            "stop_words": [
                "_russian_"
            ]
        }
    ]
}
```

### è¥¿ç­ç‰™è¯­\{#spanish}

```json
{
    "tokenizer": "standard",
    "filter": [
        "lowercase",
        {
            "type": "stemmer",
            "language": "spanish"
        },
        {
            "type": "stop",
            "stop_words": [
                "_spanish_"
            ]
        }
    ]
}
```

### æ–¯ç“¦å¸Œé‡Œè¯­\{#swahili}

```json
{
    "tokenizer": "standard",
    "filter": ["lowercase", {
        "type": "stop",
        "stop_words": [<put stop words list here>]
    }]
}
```

### åœŸè€³å…¶è¯­\{#turkish}

```json
{
    "tokenizer": "standard",
    "filter": [
        "lowercase",
        {
            "type": "stemmer",
            "language": "turkish"
        }
    ]
}
```

### ä¹Œå°”éƒ½è¯­\{#urdu}

```json
{
    "tokenizer": "icu",
    "filter": ["lowercase", {
        "type": "stop",
        "stop_words": [<put stop words list here>]
    }]
}
```

### æ··åˆæˆ–å¤šè¯­è¨€å†…å®¹\{#mixed-or-multilingual-content}

å½“å¤„ç†è·¨å¤šç§è¯­è¨€æˆ–æ–‡å­—ä½“ç³»ä¸å¯é¢„æµ‹çš„å†…å®¹æ—¶ï¼Œå»ºè®®ä½¿ç”¨ `icu` analyzerã€‚ è¯¥ Analyzer å…·å¤‡ Unicode è¯†åˆ«èƒ½åŠ›ï¼Œèƒ½æœ‰æ•ˆå¤„ç†æ··åˆæ–‡å­—å’Œç¬¦å·ã€‚

**åŸºç¡€å¤šè¯­è¨€é…ç½®**ï¼ˆä¸åŒ…å«è¯å¹²æå–ï¼‰ï¼š

```python
analyzer_params = {
    "tokenizer": "icu",
    "filter": ["lowercase", "asciifolding"]
}
```

**é«˜çº§å¤šè¯­è¨€å¤„ç†**ï¼š

- ä½¿ç”¨ multi-language analyzer é…ç½®ã€‚è¯¦æƒ…å‚è§[å¤šè¯­è¨€ Analyzer](./multi-language-analyzers)ã€‚

- åœ¨å†…å®¹ä¸­å®ç° language identifierã€‚è¯¦æƒ…å‚è§ [Language Identifier](./language-identifier-tokenizer)ã€‚

## åœ¨ Zilliz Cloud é…ç½®å’Œé¢„è§ˆ Analyzer

ä½ å¯ä»¥ç›´æ¥åœ¨ Zilliz Cloud æ§åˆ¶å°ä¸­é…ç½®å’Œæµ‹è¯• Analyzerï¼Œè€Œæ— éœ€ç¼–å†™ä»£ç ã€‚å…·ä½“å¯å‚è€ƒå¦‚ä¸‹æ¼”ç¤ºã€‚

<Supademo id="cmfxiu7c342st10k8ql0xi1av" title=""  />

