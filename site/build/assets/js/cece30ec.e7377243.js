"use strict";(self.webpackChunksite=self.webpackChunksite||[]).push([[6325],{3905:(e,n,t)=>{t.d(n,{Zo:()=>d,kt:()=>h});var a=t(7294);function i(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function r(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function s(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?r(Object(t),!0).forEach((function(n){i(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function o(e,n){if(null==e)return{};var t,a,i=function(e,n){if(null==e)return{};var t,a,i={},r=Object.keys(e);for(a=0;a<r.length;a++)t=r[a],n.indexOf(t)>=0||(i[t]=e[t]);return i}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)t=r[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(i[t]=e[t])}return i}var l=a.createContext({}),u=function(e){var n=a.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):s(s({},n),e)),t},d=function(e){var n=u(e.components);return a.createElement(l.Provider,{value:n},e.children)},c="mdxType",p={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},m=a.forwardRef((function(e,n){var t=e.components,i=e.mdxType,r=e.originalType,l=e.parentName,d=o(e,["components","mdxType","originalType","parentName"]),c=u(t),m=i,h=c["".concat(l,".").concat(m)]||c[m]||p[m]||r;return t?a.createElement(h,s(s({ref:n},d),{},{components:t})):a.createElement(h,s({ref:n},d))}));function h(e,n){var t=arguments,i=n&&n.mdxType;if("string"==typeof e||i){var r=t.length,s=new Array(r);s[0]=m;var o={};for(var l in n)hasOwnProperty.call(n,l)&&(o[l]=n[l]);o.originalType=e,o[c]="string"==typeof e?e:i,s[1]=o;for(var u=2;u<r;u++)s[u]=t[u];return a.createElement.apply(null,s)}return a.createElement.apply(null,t)}m.displayName="MDXCreateElement"},1903:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>p,frontMatter:()=>r,metadata:()=>o,toc:()=>u});var a=t(7462),i=(t(7294),t(3905));const r={slug:"/question-answering-using-zilliz-cloud-and-hugging-face",sidebar_position:2},s="\u4e0e HuggingFace \u96c6\u6210\u642d\u5efa\u95ee\u7b54\u7cfb\u7edf",o={unversionedId:"tutorials/ai-models-integration/open-services/question-answering-using-zilliz-cloud-and-hugging-face",id:"tutorials/ai-models-integration/open-services/question-answering-using-zilliz-cloud-and-hugging-face",title:"\u4e0e HuggingFace \u96c6\u6210\u642d\u5efa\u95ee\u7b54\u7cfb\u7edf",description:"\u672c\u6587\u5c06\u6f14\u793a\u5982\u4f55\u4f7f\u7528 Zilliz Cloud \u548c HuggingFace \u642d\u5efa\u95ee\u7b54\u7cfb\u7edf\u3002\u5176\u4e2d\uff0cZilliz Cloud \u8d1f\u8d23\u63d0\u4f9b\u5411\u91cf\u6570\u636e\u5e93\uff0cHuggingFace \u8d1f\u8d23\u63d0\u4f9b\u83b7\u53d6\u6307\u5b9a\u6587\u5b57\u5411\u91cf\u8868\u793a\u7684\u63a5\u53e3\u3002",source:"@site/docs/tutorials/ai-models-integration/open-services/question-answering-using-zilliz-cloud-and-hugging-face.md",sourceDirName:"tutorials/ai-models-integration/open-services",slug:"/question-answering-using-zilliz-cloud-and-hugging-face",permalink:"/docs/question-answering-using-zilliz-cloud-and-hugging-face",draft:!1,tags:[],version:"current",sidebarPosition:2,frontMatter:{slug:"/question-answering-using-zilliz-cloud-and-hugging-face",sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"\u4e0e Cohere \u96c6\u6210\u642d\u5efa\u667a\u80fd\u95ee\u7b54\u7cfb\u7edf",permalink:"/docs/question-answering-using-zilliz-cloud-and-cohere"},next:{title:"\u5f00\u6e90\u9879\u76ee",permalink:"/docs/open-source-projects"}},l={},u=[{value:"\u51c6\u5907\u5de5\u4f5c",id:"some-prep-work",level:2},{value:"\u4e3b\u8981\u53c2\u6570",id:"parameters",level:2},{value:"\u521b\u5efa Collection",id:"create-collection",level:2},{value:"\u63d2\u5165\u6570\u636e",id:"insert-data",level:2},{value:"\u6d4b\u8bd5\u95ee\u7b54",id:"ask-questions",level:2}],d={toc:u},c="wrapper";function p(e){let{components:n,...t}=e;return(0,i.kt)(c,(0,a.Z)({},d,t,{components:n,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"\u4e0e-huggingface-\u96c6\u6210\u642d\u5efa\u95ee\u7b54\u7cfb\u7edf"},"\u4e0e HuggingFace \u96c6\u6210\u642d\u5efa\u95ee\u7b54\u7cfb\u7edf"),(0,i.kt)("p",null,"\u672c\u6587\u5c06\u6f14\u793a\u5982\u4f55\u4f7f\u7528 Zilliz Cloud \u548c HuggingFace \u642d\u5efa\u95ee\u7b54\u7cfb\u7edf\u3002\u5176\u4e2d\uff0cZilliz Cloud \u8d1f\u8d23\u63d0\u4f9b\u5411\u91cf\u6570\u636e\u5e93\uff0cHuggingFace \u8d1f\u8d23\u63d0\u4f9b\u83b7\u53d6\u6307\u5b9a\u6587\u5b57\u5411\u91cf\u8868\u793a\u7684\u63a5\u53e3\u3002"),(0,i.kt)("h2",{id:"some-prep-work"},"\u51c6\u5907\u5de5\u4f5c"),(0,i.kt)("p",null,"\u672c\u793a\u4f8b\u4e2d\u7684\u811a\u672c\u9700\u8981\u5b89\u88c5 ",(0,i.kt)("strong",{parentName:"p"},"pymilvus"),"\uff0c",(0,i.kt)("strong",{parentName:"p"},"transformers")," \u548c ",(0,i.kt)("strong",{parentName:"p"},"datasets"),"\u3002\u5176\u4e2d\uff0c",(0,i.kt)("strong",{parentName:"p"},"transformers")," \u548c ",(0,i.kt)("strong",{parentName:"p"},"datasets")," \u662f HuggingFace \u63d0\u4f9b\u7684\u7528\u4e8e\u521b\u5efa\u6d41\u6c34\u7ebf\u7684\u5f00\u53d1\u5305\uff0c",(0,i.kt)("strong",{parentName:"p"},"pymilvus")," \u662f Zilliz Cloud\u7684 Python \u5ba2\u6237\u7aef\uff0c\u5982\u679c\u4f60\u7684\u7cfb\u7edf\u4e2d\u6ca1\u6709\u5b89\u88c5\u8fd9\u4e9b\u4f9d\u8d56\uff0c\u53ef\u4ee5\u4f7f\u7528\u5982\u4e0b\u547d\u4ee4\u5b8c\u6210\u5b89\u88c5\u3002"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"},"pip install transformers datasets pymilvus torch\n")),(0,i.kt)("p",null,"\u7136\u540e\uff0c\u53ef\u4ee5\u6309\u5982\u4e0b\u65b9\u5f0f\u52a0\u8f7d\u8fd9\u4e9b\u4f9d\u8d56\u3002"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility\nfrom datasets import load_dataset_builder, load_dataset, Dataset\nfrom transformers import AutoTokenizer, AutoModel\nfrom torch import clamp, sum\n")),(0,i.kt)("h2",{id:"parameters"},"\u4e3b\u8981\u53c2\u6570"),(0,i.kt)("p",null,"\u5728\u8fd9\u91cc\uff0c\u6211\u4eec\u5b9a\u4e49\u4e86\u4e00\u4e9b\u793a\u4f8b\u4e2d\u5c06\u8981\u4f7f\u7528\u7684\u4e3b\u8981\u53c2\u6570\u3002\u4f60\u9700\u8981\u6839\u636e\u5b9e\u9645\u60c5\u51b5\u548c\u53c2\u6570\u65c1\u7684\u6ce8\u91ca\u586b\u5199\u6216\u66ff\u6362\u6210\u76f8\u5e94\u7684\u5185\u5bb9\u3002"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"DATASET = 'squad'  # \u672c\u793a\u4f8b\u4f7f\u7528\u7684 HuggingFace \u6570\u636e\u96c6\nMODEL = 'bert-base-uncased'  # \u83b7\u53d6\u6307\u5b9a\u6587\u672c\u7684\u5411\u91cf\u8868\u793a\u65f6\u4f7f\u7528\u7684 Transformer \u6a21\u578b\nTOKENIZATION_BATCH_SIZE = 1000  # \u6587\u672c\u7b26\u53f7\u5316\u64cd\u4f5c\u7684\u6279\u6b21\u5927\u5c0f\nINFERENCE_BATCH_SIZE = 64  # \u63d0\u4ea4\u7ed9 Transformer \u6a21\u578b\u7684\u6279\u6b21\u5927\u5c0f\nINSERT_RATIO = .001  # \u6307\u5b9a\u9700\u8981\u63d2\u5165\u7684\u8bb0\u5f55\u6570\u91cf\u5728\u6570\u636e\u96c6\u6240\u6709\u8bb0\u5f55\u4e2d\u7684\u5360\u6bd4\nCOLLECTION_NAME = 'huggingface_db'  # \u5c06\u8981\u521b\u5efa\u7684 Colletion \u540d\u79f0\nDIMENSION = 768  # \u5411\u91cf\u7ef4\u5ea6\nLIMIT = 10  # \u6bcf\u6b21\u641c\u7d22\u8fd4\u56de\u7684\u7ed3\u679c\u6570\u91cf\nURI='https://replace-this-with-the-public-endpoint-of-your-cluster-on-zilliz-cloud'  # Cluster \u7684\u516c\u5171\u7aef\u70b9\uff0c\u4ece Zilliz Cloud \u83b7\u53d6\nUSER='replace-this-with-the-cluster-user-name'  # \u5728\u521b\u5efa Cluster \u65f6\u6307\u5b9a\u7684\u7528\u6237\u540d\nPASSWORD='replace-this-with-the-cluster-password'  # \u4e0a\u8ff0\u7528\u6237\u540d\u5bf9\u5e94\u7684\u5bc6\u7801\n")),(0,i.kt)("p",null,"\u5982\u9700\u8fdb\u4e00\u6b65\u4e86\u89e3\u4e0a\u8ff0 Transformer \u6a21\u578b\u53ca\u6570\u636e\u96c6\uff0c\u53ef\u53c2\u8003 ",(0,i.kt)("a",{parentName:"p",href:"https://huggingface.co/bert-base-uncased"},"bert-base-uncased")," \u53ca ",(0,i.kt)("a",{parentName:"p",href:"https://huggingface.co/datasets/squad"},"squad"),"\u3002"),(0,i.kt)("h2",{id:"create-collection"},"\u521b\u5efa Collection"),(0,i.kt)("p",null,"\u6211\u4eec\u9700\u8981\u4e8b\u5148\u5728 Zilliz Cloud \u4e0a\u51c6\u5907\u597d\u4e00\u4e2a Cluster\u3002\u5728\u8fd9\u4e00\u5c0f\u8282\u91cc\uff0c\u6211\u4eec\u5c06\u6f14\u793a\u5982\u4f55\u5728\u8fd9\u4e2a Cluster \u91cc\u521b\u5efa\u4e00\u4e2a Collection \u5e76\u4e3a\u5176\u521b\u5efa\u7d22\u5f15\u3002"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"# \u8fde\u63a5\u5230 Zilliz Cloud cluster\nconnections.connect(uri=URI, user=USER, password=PASSWORD, secure=True)\n\n# \u5982\u679c\u8981\u521b\u5efa\u7684 Collection \u5df2\u5b58\u5728\uff0c\u5220\u9664\u8be5 Collection\nif utility.has_collection(COLLECTION_NAME):\n    utility.drop_collection(COLLECTION_NAME)\n\n# \u521b\u5efa\u4e00\u4e2a Collection\uff0c\u6709\u5982\u4e0b4\u4e2a\u5b57\u6bb5\uff1aID\uff0c\u95ee\u9898\uff0c\u95ee\u9898\u7684\u5411\u91cf\u8868\u793a\u53ca\u5bf9\u5e94\u7684\u7b54\u6848\nfields = [\n    FieldSchema(name='id', dtype=DataType.INT64, is_primary=True, auto_id=True),\n    FieldSchema(name='original_question', dtype=DataType.VARCHAR, max_length=1000),\n    FieldSchema(name='answer', dtype=DataType.VARCHAR, max_length=1000),\n    FieldSchema(name='original_question_embedding', dtype=DataType.FLOAT_VECTOR, dim=DIMENSION)\n]\nschema = CollectionSchema(fields=fields)\ncollection = Collection(name=COLLECTION_NAME, schema=schema)\n\n# \u521b\u5efa\u4e00\u4e2a\u7c7b\u578b\u4e3a AUTOINDEX \u7684\u7d22\u5f15\nindex_params = {\n    'index_type': 'AUTOINDEX',\n    'metric_type': 'IP'\n    'params': {}\n}\ncollection.create_index(field_name=\"original_question_embedding\", index_params=index_params)\ncollection.load()\n")),(0,i.kt)("h2",{id:"insert-data"},"\u63d2\u5165\u6570\u636e"),(0,i.kt)("p",null,"\u5411 Collection \u4e2d\u63d2\u5165\u6211\u4eec\u51c6\u5907\u597d\u7684\u6570\u636e\u5206\u4e3a\u5982\u4e0b\u4e09\u6b65\uff1a"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"\u5bf9\u539f\u59cb\u63d0\u95ee\u8fdb\u884c\u7b26\u53f7\u5316\u5904\u7406\u3002")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"\u83b7\u53d6\u5b8c\u6210\u7b26\u53f7\u5316\u540e\u7684\u63d0\u95ee\u5bf9\u5e94\u7684\u5411\u91cf\u8868\u793a\u3002")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"\u5c06\u6570\u636e\u63d2\u5165\u4e4b\u524d\u521b\u5efa\u7684 Collection \u4e2d\u3002"))),(0,i.kt)("p",null,"\u5728\u672c\u793a\u4f8b\u4e2d\uff0c\u4e00\u6761\u6570\u636e\u5305\u542b\u4e00\u4e2a\u539f\u59cb\u63d0\u95ee\u3001\u8be5\u63d0\u95ee\u7684\u5411\u91cf\u5316\u8868\u793a\u53ca\u5bf9\u5e94\u7684\u7b54\u6848\u3002"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"data_dataset = load_dataset(DATASET, split='all')\n# \u751f\u6210\u4e00\u4e2a\u56fa\u5b9a\u7684\u6570\u636e\u5b50\u96c6\u3002\u5982\u9700\u751f\u6210\u4e00\u4e2a\u968f\u673a\u7684\u6570\u636e\u5b50\u96c6\uff0c\u987b\u79fb\u9664 seed \u53c2\u6570\u3002\u5982\u9700\u4e86\u89e3\u66f4\u591a\uff0c\u53ef\u53c2\u8003 <https://huggingface.co/docs/datasets/v2.9.0/en/package_reference/main_classes#datasets.Dataset.train_test_split.seed>\ndata_dataset = data_dataset.train_test_split(test_size=INSERT_RATIO, seed = 42)['test']\n# \u6e05\u7406\u6570\u636e\u96c6\u7684\u6570\u636e\u7ed3\u6784\ndata_dataset = data_dataset.map(lambda val: {'answer': val['answers']['text'][0]}, remove_columns=['answers'])\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL)\n\n# \u5bf9\u63d0\u95ee\u8fdb\u884c\u7b26\u53f7\u5316\u5904\u7406\uff0c\u4ee5\u4fbf\u6ee1\u8db3 BERT \u5bf9\u6570\u636e\u7684\u683c\u5f0f\u8981\u6c42\ndef tokenize_question(batch):\n    results = tokenizer(batch['question'], add_special_tokens = True, truncation = True, padding = \"max_length\", return_attention_mask = True, return_tensors = \"pt\")\n    batch['input_ids'] = results['input_ids']\n    batch['token_type_ids'] = results['token_type_ids']\n    batch['attention_mask'] = results['attention_mask']\n    return batch\n\n# \u4e3a\u6bcf\u4e2a\u8f93\u5165\u751f\u6210\u5bf9\u5e94\u7684\u7b26\u53f7\ndata_dataset = data_dataset.map(tokenize_question, batch_size=TOKENIZATION_BATCH_SIZE, batched=True)\n# \u5c06\u8f93\u51fa\u683c\u5f0f\u8bbe\u7f6e\u4e3a torch \u4ee5\u4fbf\u53ef\u4ee5\u63d0\u4ea4\u7ed9 Embedding \u6a21\u578b\ndata_dataset.set_format('torch', columns=['input_ids', 'token_type_ids', 'attention_mask'], output_all_columns=True)\n\nmodel = AutoModel.from_pretrained(MODEL)\n# \u5728\u67d0\u4e2a\u63d0\u95ee\u5b8c\u6210\u7b26\u53f7\u5316\u5904\u7406\u540e\uff0c\u83b7\u53d6\u5176\u5bf9\u5e94\u7684\u5411\u91cf\u5316\u8868\u793a\uff0c\u7136\u540e\u63d0\u53d6\u4e0e\u9690\u85cf\u5c42\u6ce8\u610f\u529b\u63a9\u7801\u6709\u5173\u7684\u5e73\u5747\u6c60\ndef embed(batch):\n    sentence_embs = model(\n                input_ids=batch['input_ids'],\n                token_type_ids=batch['token_type_ids'],\n                attention_mask=batch['attention_mask']\n                )[0]\n    input_mask_expanded = batch['attention_mask'].unsqueeze(-1).expand(sentence_embs.size()).float()\n    batch['question_embedding'] = sum(sentence_embs * input_mask_expanded, 1) / clamp(input_mask_expanded.sum(1), min=1e-9)\n    return batch\n\ndata_dataset = data_dataset.map(embed, remove_columns=['input_ids', 'token_type_ids', 'attention_mask'], batched = True, batch_size=INFERENCE_BATCH_SIZE)\n\n# \u7531\u4e8eVARCHAR\u6570\u636e\u7c7b\u578b\u7684\u7ea6\u675f\uff0c\u6b64\u5904\u9650\u5236\u4e86\u95ee\u9898\u7684\u957f\u5ea6\ndef insert_function(batch):\n    insertable = [\n        batch['question'],\n        [x[:995] + '...' if len(x) > 999 else x for x in batch['answer']],\n        batch['question_embedding'].tolist()\n    ]    \n    collection.insert(insertable)\n\ndata_dataset.map(insert_function, batched=True, batch_size=64)\ncollection.flush()\n")),(0,i.kt)("h2",{id:"ask-questions"},"\u6d4b\u8bd5\u95ee\u7b54"),(0,i.kt)("p",null,"\u5728\u6211\u4eec\u5411 Collection \u4e2d\u63d2\u5165\u6240\u6709\u7684\u6570\u636e\u540e\uff0c\u5c31\u53ef\u4ee5\u5f00\u59cb\u5411\u8fd9\u4e2a\u95ee\u7b54\u7cfb\u7edf\u63d0\u95ee\u5e76\u83b7\u53d6\u4e0e\u6211\u4eec\u7684\u63d0\u95ee\u6700\u76f8\u8fd1\u7684\u63d0\u95ee\u5bf9\u5e94\u7684\u7b54\u6848\u4e86\u3002"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"questions = {'question':['When did the premier league start?', 'Where did people learn russian?']}\nquestion_dataset = Dataset.from_dict(questions)\n\nquestion_dataset = question_dataset.map(tokenize_question, batched = True, batch_size=TOKENIZATION_BATCH_SIZE)\nquestion_dataset.set_format('torch', columns=['input_ids', 'token_type_ids', 'attention_mask'], output_all_columns=True)\nquestion_dataset = question_dataset.map(embed, remove_columns=['input_ids', 'token_type_ids', 'attention_mask'], batched = True, batch_size=INFERENCE_BATCH_SIZE)\n\ndef search(batch):\n    res = collection.search(batch['question_embedding'].tolist(), anns_field='original_question_embedding', param = {}, output_fields=['answer', 'original_question'], limit = LIMIT)\n    overall_id = []\n    overall_distance = []\n    overall_answer = []\n    overall_original_question = []\n    for hits in res:\n        ids = []\n        distance = []\n        answer = []\n        original_question = []\n        for hit in hits:\n            ids.append(hit.id)\n            distance.append(hit.distance)\n            answer.append(hit.entity.get('answer'))\n            original_question.append(hit.entity.get('original_question'))\n        overall_id.append(ids)\n        overall_distance.append(distance)\n        overall_answer.append(answer)\n        overall_original_question.append(original_question)\n    return {\n        'id': overall_id,\n        'distance': overall_distance,\n        'answer': overall_answer,\n        'original_question': overall_original_question\n    }\nquestion_dataset = question_dataset.map(search, batched=True, batch_size = 1)\nfor x in question_dataset:\n    print()\n    print('Question:')\n    print(x['question'])\n    print('Answer, Distance, Original Question')\n    for x in zip(x['answer'], x['distance'], x['original_question']):\n        print(x)\n")),(0,i.kt)("p",null,"\u5982\u679c\u672a\u8bbe\u7f6e ",(0,i.kt)("inlineCode",{parentName:"p"},"train_test_split()")," \u65b9\u6cd5\u7684 ",(0,i.kt)("inlineCode",{parentName:"p"},"seed")," \u53c2\u6570\uff0c\u8f93\u51fa\u7684\u7ed3\u679c\u53ef\u80fd\u4f1a\u56e0\u4f60\u4e0b\u8f7d\u7684\u6570\u636e\u5b50\u96c6\u7684\u4e0d\u540c\u800c\u4e0e\u793a\u4f8b\u5b58\u5728\u5dee\u5f02\u3002"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"Question:\nWhen did the premier league start?\nAnswer, Distance, Original Question\n('1992', tensor(19.1790), 'In what year was the Premier League created?')\n('1787', tensor(35.1203), 'When was the Tower constructed?')\n('until 1870', tensor(36.0302), 'When did the Papal States exist?')\n('1981', tensor(36.0476), \"When was ZE's Mutant Disco released?\")\n('Sunday Times University of the Year award', tensor(39.2945), 'What did Newcastle University win in 2000?')\n('terrorism', tensor(39.7199), 'What issue did Spielberg address in his movie Munich?')\n('2019', tensor(40.9740), 'When will Argo be launched?')\n('October 1992', tensor(41.4449), 'When were free elections held?')\n('Misrata', tensor(41.7602), 'Where did an ambulance take Gaddafi after he was murdered?')\n('Poland, Bulgaria, the Czech Republic, Slovakia, Hungary, Albania, former East Germany and Cuba', tensor(42.0978), 'Where was Russian schooling mandatory in the 20th century?')\n\nQuestion:\nWhere did people learn russian?\nAnswer, Distance, Original Question\n('Poland, Bulgaria, the Czech Republic, Slovakia, Hungary, Albania, former East Germany and Cuba', tensor(31.6751), 'Where was Russian schooling mandatory in the 20th century?')\n('accomplishments', tensor(34.7001), 'What did Czech historians emphasize about their countrymen?')\n('until 1870', tensor(37.2057), 'When did the Papal States exist?')\n('1787', tensor(38.3059), 'When was the Tower constructed?')\n('October 1992', tensor(40.4033), 'When were free elections held?')\n('salt and iron', tensor(41.3883), 'What natural resources did the Chinese government have a monopoly on?')\n('1992', tensor(41.5846), 'In what year was the Premier League created?')\n('6,000 years', tensor(41.7438), 'How old did biblical scholars think the Earth was?')\n('traders', tensor(42.1737), 'Along with fishermen, what sort of Japanese people visited the Marshalls?')\n('1981', tensor(44.3291), \"When was ZE's Mutant Disco released?\")\n")))}p.isMDXComponent=!0}}]);